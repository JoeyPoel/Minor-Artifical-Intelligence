{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Embeddings, Conv1D en Recurrente netwerken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Flatten, Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 1: Verover de data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We gebruiken de IMDB dataset met filmrecensies. Deze hebben we tijdens de bootcamp ook al eens bekeken. ter herinnering: de labels zijn binair en geven aan of een film wel of geen aanrader is volgens de reviews.\n",
    "\n",
    "We maken het ons zelf iets moeilijker door van elke review alleen de eerste 20 woorden te gebruiken."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.datasets import imdb\n",
    "from keras import preprocessing\n",
    "\n",
    "max_features = 10000\n",
    "maxlen = 20 # gebruik alleen de eerste 20 woorden van iedere review (voor efficiency)\n",
    "\n",
    "(x_train, y_train), (x_test, y_test) = imdb.load_data(num_words = max_features)\n",
    "\n",
    "# gebruik alleen de eerste 20 woorden\n",
    "# vul sequences korter dan 20 woorden aan met nullen\n",
    "x_train = preprocessing.sequence.pad_sequences(x_train, maxlen = maxlen)\n",
    "x_test = preprocessing.sequence.pad_sequences(x_test, maxlen = maxlen)\n",
    "\n",
    "x_val_set = x_train[:10000]\n",
    "x_train_set = x_train[10000:]\n",
    "\n",
    "y_val_set = y_train[:10000]\n",
    "y_train_set = y_train[10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(15000, 20) (15000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_set.shape, y_train_set.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 2: Embedding"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We trainen een embedding layer in combinatie met een Dense netwerk. In onderstaande code zijn de lagen voor de embedding al ingevuld. Maak het netwerk af met een of meer dense lagen, compileer en train dit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Embedding\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(10000, 16, input_length = maxlen))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(units=128, activation='relu'))\n",
    "model.add(Dense(units=1, activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "469/469 [==============================] - 5s 7ms/step - loss: 0.5866 - accuracy: 0.6701 - val_loss: 0.4948 - val_accuracy: 0.7569\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.3465 - accuracy: 0.8516 - val_loss: 0.5510 - val_accuracy: 0.7399\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.1362 - accuracy: 0.9549 - val_loss: 0.7684 - val_accuracy: 0.7231\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 3s 7ms/step - loss: 0.0318 - accuracy: 0.9925 - val_loss: 0.9908 - val_accuracy: 0.7193\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 3s 6ms/step - loss: 0.0053 - accuracy: 0.9999 - val_loss: 1.1330 - val_accuracy: 0.7222\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train_set, y_train_set,\n",
    "                    batch_size=32,\n",
    "                    epochs=5,\n",
    "                    validation_data=(x_val_set, y_val_set))\n",
    "\n",
    "# Save the model\n",
    "model.save('my_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stap 3: 1D Convolutie"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenteer met een netwerk met een Embedding en een of meer `Conv1D` lagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\joeyw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:6642: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Epoch 1/5\n",
      "469/469 [==============================] - 11s 21ms/step - loss: 0.6244 - accuracy: 0.6420 - val_loss: 0.5684 - val_accuracy: 0.6996\n",
      "Epoch 2/5\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.4424 - accuracy: 0.7969 - val_loss: 0.5855 - val_accuracy: 0.6981\n",
      "Epoch 3/5\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.2578 - accuracy: 0.8994 - val_loss: 0.7025 - val_accuracy: 0.6851\n",
      "Epoch 4/5\n",
      "469/469 [==============================] - 10s 21ms/step - loss: 0.1106 - accuracy: 0.9692 - val_loss: 0.8982 - val_accuracy: 0.6784\n",
      "Epoch 5/5\n",
      "469/469 [==============================] - 11s 23ms/step - loss: 0.0364 - accuracy: 0.9929 - val_loss: 1.0981 - val_accuracy: 0.6692\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Conv1D, MaxPooling1D, Flatten, Dense\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "# Embedding layer\n",
    "model.add(Embedding(max_features, 128, input_length=maxlen))\n",
    "\n",
    "# Conv1D layer\n",
    "model.add(Conv1D(32, 7, activation='relu'))\n",
    "\n",
    "# MaxPooling1D layer\n",
    "model.add(MaxPooling1D(5))\n",
    "\n",
    "# Flatten layer\n",
    "model.add(Flatten())\n",
    "\n",
    "# Dense layer\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(x_train_set, y_train_set,\n",
    "                    batch_size=32,\n",
    "                    epochs=5,\n",
    "                    validation_data=(x_val_set, y_val_set))\n",
    "\n",
    "# Save the model\n",
    "model.save('my_model_with_maxpooling1d.keras')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## BONUS: pre-trained embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
