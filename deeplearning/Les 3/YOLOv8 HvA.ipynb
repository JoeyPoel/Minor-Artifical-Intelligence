{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "t6MPjfT5NrKQ"
   },
   "source": [
    "# YOLO v8 for HvA\n",
    "\n",
    "- Minor Applied AI, Computer Vision les 4 \n",
    "- Michiel Bontenbal & Maarten Post\n",
    "- woensdag 3 april 2024\n",
    "\n",
    "\n",
    "Source: https://colab.research.google.com/github/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb#scrollTo=zR9ZbuQCH7FX\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7mGmQbAO5pQb"
   },
   "source": [
    "# Setup\n",
    "\n",
    "\n",
    "YOLO is nu van een bedrijf Ultralytics en we gaan hun repo gebruiken. Zie https://www.ultralytics.com/nl\n",
    "\n",
    "Pip install `ultralytics` and [dependencies](https://github.com/ultralytics/ultralytics/blob/main/pyproject.toml) and check software and hardware."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 329
    },
    "executionInfo": {
     "elapsed": 216,
     "status": "error",
     "timestamp": 1712056873234,
     "user": {
      "displayName": "Michiel Bontenbal",
      "userId": "03976569418489878594"
     },
     "user_tz": -120
    },
    "id": "wbvMlHd_QwMG",
    "outputId": "2792633d-7f18-4365-d60d-9e299012f017"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.42  Python-3.11.7 torch-2.2.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
      "Setup complete  (16 CPUs, 15.4 GB RAM, 278.1/475.4 GB disk)\n"
     ]
    }
   ],
   "source": [
    "%pip install ultralytics\n",
    "import ultralytics\n",
    "ultralytics.checks()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "4JnkELT0cIJg"
   },
   "source": [
    "# 1. Predict with CLI\n",
    "\n",
    "YOLOv8 may be used directly in the Command Line Interface (CLI) with a `yolo` command \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "zR9ZbuQCH7FX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n.pt to 'yolov8n.pt'..."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0.00/6.23M [00:00<?, ?B/s]\n",
      " 22%|â–ˆâ–ˆâ–       | 1.34M/6.23M [00:00<00:00, 14.0MB/s]\n",
      " 49%|â–ˆâ–ˆâ–ˆâ–ˆâ–‰     | 3.05M/6.23M [00:00<00:00, 16.2MB/s]\n",
      " 84%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ– | 5.23M/6.23M [00:00<00:00, 19.2MB/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.23M/6.23M [00:00<00:00, 18.9MB/s]\n",
      "\n",
      "  0%|          | 0.00/165k [00:00<?, ?B/s]\n",
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 165k/165k [00:00<00:00, 9.49MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Ultralytics YOLOv8.1.42 ðŸš€ Python-3.11.7 torch-2.2.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "Downloading https://ultralytics.com/images/zidane.jpg to 'zidane.jpg'...\n",
      "image 1/1 c:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\zidane.jpg: 384x640 2 persons, 1 tie, 217.3ms\n",
      "Speed: 11.4ms preprocess, 217.3ms inference, 18.3ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n",
      "Ultralytics YOLOv8.1.42 ðŸš€ Python-3.11.7 torch-2.2.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
      "YOLOv8n summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n",
      "\n",
      "Found https://ultralytics.com/images/zidane.jpg locally at zidane.jpg\n",
      "image 1/1 c:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\zidane.jpg: 384x640 2 persons, 1 tie, 213.1ms\n",
      "Speed: 5.5ms preprocess, 213.1ms inference, 3.0ms postprocess per image at shape (1, 3, 384, 640)\n",
      "Results saved to \u001b[1mruns\\detect\\predict2\u001b[0m\n",
      "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
     ]
    }
   ],
   "source": [
    "# Run inference on an image with YOLOv8n\n",
    "!yolo predict model=yolov8n.pt source='https://ultralytics.com/images/zidane.jpg'\n",
    "!yolo predict model=yolov8n.pt source='https://ultralytics.com/images/zidane.jpg'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hkAzDWJ7cWTr"
   },
   "source": [
    "&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\n",
    "<img align=\"left\" src=\"https://user-images.githubusercontent.com/26833433/212889447-69e5bdf1-5800-4e29-835e-2ed2336dede2.jpg\" width=\"600\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kUMOQ0OeDBJG"
   },
   "source": [
    "# 2. Python Usage\n",
    "\n",
    "YOLOv8 was reimagined using Python-first principles for the most seamless Python YOLO experience yet. YOLOv8 models can be loaded from a trained checkpoint or created from scratch. Then methods are used to train, val, predict, and export the model. See detailed Python usage examples in the [YOLOv8 Python Docs](https://docs.ultralytics.com/usage/python/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "bpF9-vS_DAaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.42  Python-3.11.7 torch-2.2.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco128.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train\n",
      "\n",
      "Dataset 'coco128.yaml' images not found , missing path 'C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco128\\images\\train2017'\n",
      "Downloading https://ultralytics.com/assets/coco128.zip to 'C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco128.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.66M/6.66M [00:00<00:00, 14.7MB/s]\n",
      "Unzipping C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco128.zip to C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco128...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 263/263 [00:00<00:00, 665.11file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset download success  (3.0s), saved to \u001b[1mC:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\u001b[0m\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\joeyw\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 755k/755k [00:00<00:00, 6.06MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\joeyw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco128\\labels\\train2017... 126 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 311.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco128\\labels\\train2017.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco128\\labels\\train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      1.135      1.433      1.236        278        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:13<00:00,  9.15s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:28<00:00,  7.00s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.657      0.534      0.615      0.457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G      1.111      1.346      1.238        167        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:12<00:00,  9.12s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:29<00:00,  7.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.681      0.541      0.625      0.465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      1.199      1.409      1.239        239        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:14<00:00,  9.33s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:29<00:00,  7.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.656      0.554      0.631      0.471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.089 hours.\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\last.pt, 6.5MB\n",
      "Optimizer stripped from runs\\detect\\train\\weights\\best.pt, 6.5MB\n",
      "\n",
      "Validating runs\\detect\\train\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.42  Python-3.11.7 torch-2.2.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
      "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:20<00:00,  5.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.657      0.554      0.631       0.47\n",
      "                person        128        254      0.805      0.684      0.768      0.545\n",
      "               bicycle        128          6      0.515      0.333      0.327      0.282\n",
      "                   car        128         46      0.803      0.217      0.282      0.174\n",
      "            motorcycle        128          5      0.683      0.869      0.898      0.675\n",
      "              airplane        128          6       0.83      0.818      0.927      0.708\n",
      "                   bus        128          7      0.718      0.714       0.73      0.641\n",
      "                 train        128          3      0.564      0.667      0.775      0.687\n",
      "                 truck        128         12          1      0.456      0.522      0.329\n",
      "                  boat        128          6      0.279      0.167      0.433      0.264\n",
      "         traffic light        128         14      0.659      0.214      0.204      0.139\n",
      "             stop sign        128          2       0.98          1      0.995      0.711\n",
      "                 bench        128          9      0.841      0.591      0.633      0.381\n",
      "                  bird        128         16      0.924      0.762       0.89      0.537\n",
      "                   cat        128          4      0.868          1      0.995      0.835\n",
      "                   dog        128          9      0.648      0.889      0.852      0.599\n",
      "                 horse        128          2      0.594          1      0.995      0.464\n",
      "              elephant        128         17      0.839      0.765      0.908      0.676\n",
      "                  bear        128          1      0.617          1      0.995      0.995\n",
      "                 zebra        128          4      0.853          1      0.995      0.965\n",
      "               giraffe        128          9      0.834          1      0.962      0.723\n",
      "              backpack        128          6      0.605      0.333      0.382      0.235\n",
      "              umbrella        128         18      0.748      0.494      0.633      0.425\n",
      "               handbag        128         19      0.569     0.0744      0.185     0.0976\n",
      "                   tie        128          7      0.799      0.714      0.677      0.455\n",
      "              suitcase        128          4      0.639          1      0.828      0.622\n",
      "               frisbee        128          5      0.609        0.8       0.76      0.688\n",
      "                  skis        128          1      0.625          1      0.995      0.497\n",
      "             snowboard        128          7      0.703      0.714      0.764      0.506\n",
      "           sports ball        128          6      0.588      0.333      0.477      0.269\n",
      "                  kite        128         10      0.816        0.5      0.588      0.215\n",
      "          baseball bat        128          4      0.408      0.362      0.373      0.187\n",
      "        baseball glove        128          7      0.656      0.429       0.43      0.295\n",
      "            skateboard        128          5      0.759        0.6      0.599      0.446\n",
      "         tennis racket        128          7      0.741      0.414      0.502      0.342\n",
      "                bottle        128         18      0.501      0.389      0.355       0.21\n",
      "            wine glass        128         16      0.575      0.562      0.558      0.329\n",
      "                   cup        128         36      0.615      0.267      0.399      0.283\n",
      "                  fork        128          6      0.581      0.167      0.296      0.206\n",
      "                 knife        128         16      0.635      0.544      0.603      0.364\n",
      "                 spoon        128         22      0.613      0.227       0.34      0.186\n",
      "                  bowl        128         28      0.652      0.679      0.642      0.535\n",
      "                banana        128          1          0          0      0.142      0.042\n",
      "              sandwich        128          2      0.383        0.5      0.662      0.662\n",
      "                orange        128          4          1      0.357      0.995      0.666\n",
      "              broccoli        128         11      0.418      0.198      0.271      0.222\n",
      "                carrot        128         24      0.685      0.543      0.692      0.448\n",
      "               hot dog        128          2      0.652      0.956      0.828      0.796\n",
      "                 pizza        128          5      0.792          1      0.995      0.844\n",
      "                 donut        128         14      0.645          1      0.917       0.83\n",
      "                  cake        128          4      0.735          1      0.995       0.88\n",
      "                 chair        128         35      0.479      0.486      0.466      0.266\n",
      "                 couch        128          6      0.404      0.333      0.641       0.49\n",
      "          potted plant        128         14       0.69      0.643      0.729        0.5\n",
      "                   bed        128          3       0.76      0.667       0.83      0.689\n",
      "          dining table        128         13       0.46      0.615      0.496      0.395\n",
      "                toilet        128          2      0.623        0.5      0.828      0.796\n",
      "                    tv        128          2      0.408        0.5      0.695      0.656\n",
      "                laptop        128          3          1      0.341      0.764      0.602\n",
      "                 mouse        128          2          1          0     0.0483    0.00483\n",
      "                remote        128          8      0.838        0.5      0.581      0.505\n",
      "            cell phone        128          8          0          0     0.0578     0.0361\n",
      "             microwave        128          3      0.486      0.667       0.83      0.733\n",
      "                  oven        128          5      0.462        0.4      0.343      0.273\n",
      "                  sink        128          6      0.359      0.167      0.231      0.147\n",
      "          refrigerator        128          5      0.691        0.4      0.648      0.525\n",
      "                  book        128         29      0.642      0.125      0.376      0.189\n",
      "                 clock        128          9       0.81      0.778      0.895       0.74\n",
      "                  vase        128          2      0.365          1      0.828      0.795\n",
      "              scissors        128          1          1          0      0.249     0.0802\n",
      "            teddy bear        128         21      0.887      0.375      0.624       0.43\n",
      "            toothbrush        128          5       0.71      0.503      0.702      0.442\n",
      "Speed: 3.0ms preprocess, 129.5ms inference, 0.0ms loss, 5.2ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train\u001b[0m\n",
      "Ultralytics YOLOv8.1.42  Python-3.11.7 torch-2.2.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
      "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco128\\labels\\train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<?, ?it/s]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:16<00:00,  2.12s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.656      0.561      0.629      0.467\n",
      "                person        128        254      0.805      0.681      0.769      0.545\n",
      "               bicycle        128          6      0.509      0.333      0.323       0.28\n",
      "                   car        128         46      0.799      0.217      0.282      0.174\n",
      "            motorcycle        128          5      0.684      0.872      0.898      0.675\n",
      "              airplane        128          6       0.83      0.819      0.927      0.708\n",
      "                   bus        128          7      0.634      0.714      0.729       0.64\n",
      "                 train        128          3      0.563      0.667      0.789      0.698\n",
      "                 truck        128         12       0.92      0.417      0.503      0.288\n",
      "                  boat        128          6      0.315      0.239      0.394      0.234\n",
      "         traffic light        128         14      0.688      0.214      0.205       0.14\n",
      "             stop sign        128          2      0.975          1      0.995      0.713\n",
      "                 bench        128          9      0.843        0.6      0.633      0.381\n",
      "                  bird        128         16      0.924      0.763      0.888      0.535\n",
      "                   cat        128          4      0.864          1      0.995      0.835\n",
      "                   dog        128          9      0.647      0.889      0.852        0.6\n",
      "                 horse        128          2      0.592          1      0.995      0.464\n",
      "              elephant        128         17      0.836      0.765      0.908      0.676\n",
      "                  bear        128          1      0.616          1      0.995      0.995\n",
      "                 zebra        128          4      0.853          1      0.995      0.965\n",
      "               giraffe        128          9      0.739          1      0.975      0.759\n",
      "              backpack        128          6      0.616      0.333      0.381      0.232\n",
      "              umbrella        128         18      0.748      0.496      0.629      0.423\n",
      "               handbag        128         19      0.575     0.0764      0.183     0.0968\n",
      "                   tie        128          7      0.798      0.714      0.677      0.454\n",
      "              suitcase        128          4      0.635          1      0.828      0.622\n",
      "               frisbee        128          5      0.607        0.8      0.759      0.688\n",
      "                  skis        128          1      0.618          1      0.995      0.497\n",
      "             snowboard        128          7      0.701      0.714      0.757      0.506\n",
      "           sports ball        128          6      0.587      0.333      0.464      0.263\n",
      "                  kite        128         10      0.813        0.5      0.589      0.216\n",
      "          baseball bat        128          4      0.407       0.25      0.348      0.199\n",
      "        baseball glove        128          7      0.642      0.429       0.43      0.316\n",
      "            skateboard        128          5      0.823        0.6      0.599      0.426\n",
      "         tennis racket        128          7      0.742      0.415      0.502      0.327\n",
      "                bottle        128         18       0.47      0.389      0.379      0.225\n",
      "            wine glass        128         16      0.587      0.562      0.531       0.32\n",
      "                   cup        128         36      0.606        0.3      0.419      0.292\n",
      "                  fork        128          6       0.57      0.167      0.238      0.184\n",
      "                 knife        128         16      0.557      0.551      0.588      0.358\n",
      "                 spoon        128         22      0.585      0.182      0.341      0.193\n",
      "                  bowl        128         28      0.662      0.679      0.663      0.507\n",
      "                banana        128          1          0          0     0.0995     0.0379\n",
      "              sandwich        128          2       0.31        0.5      0.414      0.414\n",
      "                orange        128          4          1      0.361      0.995      0.666\n",
      "              broccoli        128         11      0.351      0.182      0.262       0.21\n",
      "                carrot        128         24      0.703      0.625      0.686      0.441\n",
      "               hot dog        128          2      0.642      0.925      0.828      0.796\n",
      "                 pizza        128          5      0.875          1      0.995      0.843\n",
      "                 donut        128         14      0.645          1      0.913      0.831\n",
      "                  cake        128          4      0.634          1      0.995       0.88\n",
      "                 chair        128         35      0.475      0.486      0.463      0.257\n",
      "                 couch        128          6       0.51        0.5      0.738      0.579\n",
      "          potted plant        128         14      0.677      0.643      0.729      0.501\n",
      "                   bed        128          3          1      0.924      0.995      0.707\n",
      "          dining table        128         13      0.522      0.615      0.488      0.389\n",
      "                toilet        128          2      0.621        0.5      0.828      0.796\n",
      "                    tv        128          2      0.407        0.5      0.695      0.656\n",
      "                laptop        128          3          1      0.344      0.708      0.566\n",
      "                 mouse        128          2          1          0     0.0694    0.00694\n",
      "                remote        128          8      0.837        0.5      0.608      0.522\n",
      "            cell phone        128          8          0          0     0.0578     0.0361\n",
      "             microwave        128          3      0.484      0.667       0.83      0.733\n",
      "                  oven        128          5      0.431        0.4      0.343      0.273\n",
      "                  sink        128          6      0.371      0.167      0.183      0.129\n",
      "          refrigerator        128          5       0.69        0.4      0.648      0.515\n",
      "                  book        128         29      0.657      0.133      0.378      0.196\n",
      "                 clock        128          9      0.808      0.778      0.895       0.74\n",
      "                  vase        128          2      0.363          1      0.828      0.795\n",
      "              scissors        128          1          1          0      0.249     0.0799\n",
      "            teddy bear        128         21      0.887      0.376      0.622      0.428\n",
      "            toothbrush        128          5      0.665        0.6      0.743      0.469\n",
      "Speed: 2.1ms preprocess, 107.3ms inference, 0.0ms loss, 4.3ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train2\u001b[0m\n",
      "\n",
      "Downloading https://ultralytics.com/images/bus.jpg to 'bus.jpg'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 476k/476k [00:00<00:00, 18.5MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1 c:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 189.8ms\n",
      "Speed: 5.7ms preprocess, 189.8ms inference, 3.5ms postprocess per image at shape (1, 3, 640, 480)\n",
      "Ultralytics YOLOv8.1.42  Python-3.11.7 torch-2.2.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
      "\n",
      "\u001b[34m\u001b[1mPyTorch:\u001b[0m starting from 'runs\\detect\\train\\weights\\best.pt' with input shape (1, 3, 640, 640) BCHW and output shape(s) (1, 84, 8400) (6.2 MB)\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m Ultralytics requirement ['onnx>=1.12.0'] not found, attempting AutoUpdate...\n",
      "Collecting onnx>=1.12.0\n",
      "  Obtaining dependency information for onnx>=1.12.0 from https://files.pythonhosted.org/packages/aa/d0/0514d02d2e84e7bb48a105877eae4065e54d7dabb60d0b60214fe2677346/onnx-1.16.0-cp311-cp311-win_amd64.whl.metadata\n",
      "  Downloading onnx-1.16.0-cp311-cp311-win_amd64.whl.metadata (16 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\joeyw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnx>=1.12.0) (1.26.4)\n",
      "Requirement already satisfied: protobuf>=3.20.2 in c:\\users\\joeyw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (from onnx>=1.12.0) (4.23.4)\n",
      "Downloading onnx-1.16.0-cp311-cp311-win_amd64.whl (14.4 MB)\n",
      "   ---------------------------------------- 14.4/14.4 MB 24.2 MB/s eta 0:00:00\n",
      "Installing collected packages: onnx\n",
      "Successfully installed onnx-1.16.0\n",
      "\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m AutoUpdate success  35.2s, installed 1 package: ['onnx>=1.12.0']\n",
      "\u001b[31m\u001b[1mrequirements:\u001b[0m  \u001b[1mRestart runtime or rerun command for updates to take effect\u001b[0m\n",
      "\n",
      "\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m starting export with onnx 1.16.0 opset 17...\n",
      "\u001b[34m\u001b[1mONNX:\u001b[0m export success  37.4s, saved as 'runs\\detect\\train\\weights\\best.onnx' (12.2 MB)\n",
      "\n",
      "Export complete (39.8s)\n",
      "Results saved to \u001b[1mC:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\runs\\detect\\train\\weights\u001b[0m\n",
      "Predict:         yolo predict task=detect model=runs\\detect\\train\\weights\\best.onnx imgsz=640  \n",
      "Validate:        yolo val task=detect model=runs\\detect\\train\\weights\\best.onnx imgsz=640 data=C:\\Users\\joeyw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\ultralytics\\cfg\\datasets\\coco128.yaml  \n",
      "Visualize:       https://netron.app\n"
     ]
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load a model\n",
    "model = YOLO('yolov8n.yaml')  # build a new model from scratch\n",
    "model = YOLO('yolov8n.pt')  # load a pretrained model (recommended for training)\n",
    "\n",
    "# Use the model\n",
    "results = model.train(data='coco128.yaml', epochs=3)  # train the model\n",
    "results = model.val()  # evaluate model performance on the validation set\n",
    "results = model('https://ultralytics.com/images/bus.jpg')  # predict on an image\n",
    "results = model.export(format='onnx')  # export the model to ONNX format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Phm9ccmOKye5"
   },
   "source": [
    "# 3. Tasks\n",
    "\n",
    "YOLOv8 can train, val, predict and export models for the most common tasks in vision AI: [Detect](https://docs.ultralytics.com/tasks/detect/), [Segment](https://docs.ultralytics.com/tasks/segment/), [Classify](https://docs.ultralytics.com/tasks/classify/) and [Pose](https://docs.ultralytics.com/tasks/pose/). See [YOLOv8 Tasks Docs](https://docs.ultralytics.com/tasks/) for more information.\n",
    "\n",
    "<br><img width=\"1024\" src=\"https://raw.githubusercontent.com/ultralytics/assets/main/im/banner-tasks.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yq26lwpYK1lq"
   },
   "source": [
    "## 1. Detection\n",
    "\n",
    "YOLOv8 _detection_ models have no suffix and are the default YOLOv8 models, i.e. `yolov8n.pt` and are pretrained on COCO. See [Detection Docs](https://docs.ultralytics.com/tasks/detect/) for full details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "8Go5qqS9LbC5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.42  Python-3.11.7 torch-2.2.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=coco128.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train3, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train3\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    897664  ultralytics.nn.modules.head.Detect           [80, [64, 128, 256]]          \n",
      "Model summary: 225 layers, 3157200 parameters, 3157184 gradients, 8.9 GFLOPs\n",
      "\n",
      "Transferred 355/355 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\detect\\train3', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco128\\labels\\train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<?, ?it/s]\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco128\\labels\\train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train3\\labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train3\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      1.135      1.433      1.236        278        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:03<00:00,  7.89s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:19<00:00,  4.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.657      0.534      0.615      0.457\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G      1.111      1.346      1.238        167        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:54<00:00,  6.87s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:21<00:00,  5.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.681      0.541      0.625      0.465\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      1.199      1.409      1.239        239        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [00:55<00:00,  6.91s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:21<00:00,  5.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.656      0.554      0.631      0.471\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.069 hours.\n",
      "Optimizer stripped from runs\\detect\\train3\\weights\\last.pt, 6.5MB\n",
      "Optimizer stripped from runs\\detect\\train3\\weights\\best.pt, 6.5MB\n",
      "\n",
      "Validating runs\\detect\\train3\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.42  Python-3.11.7 torch-2.2.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
      "Model summary (fused): 168 layers, 3151904 parameters, 0 gradients, 8.7 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:15<00:00,  3.82s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.657      0.554      0.631       0.47\n",
      "                person        128        254      0.805      0.684      0.768      0.545\n",
      "               bicycle        128          6      0.515      0.333      0.327      0.282\n",
      "                   car        128         46      0.803      0.217      0.282      0.174\n",
      "            motorcycle        128          5      0.683      0.869      0.898      0.675\n",
      "              airplane        128          6       0.83      0.818      0.927      0.708\n",
      "                   bus        128          7      0.718      0.714       0.73      0.641\n",
      "                 train        128          3      0.564      0.667      0.775      0.687\n",
      "                 truck        128         12          1      0.456      0.522      0.329\n",
      "                  boat        128          6      0.279      0.167      0.433      0.264\n",
      "         traffic light        128         14      0.659      0.214      0.204      0.139\n",
      "             stop sign        128          2       0.98          1      0.995      0.711\n",
      "                 bench        128          9      0.841      0.591      0.633      0.381\n",
      "                  bird        128         16      0.924      0.762       0.89      0.537\n",
      "                   cat        128          4      0.868          1      0.995      0.835\n",
      "                   dog        128          9      0.648      0.889      0.852      0.599\n",
      "                 horse        128          2      0.594          1      0.995      0.464\n",
      "              elephant        128         17      0.839      0.765      0.908      0.676\n",
      "                  bear        128          1      0.617          1      0.995      0.995\n",
      "                 zebra        128          4      0.853          1      0.995      0.965\n",
      "               giraffe        128          9      0.834          1      0.962      0.723\n",
      "              backpack        128          6      0.605      0.333      0.382      0.235\n",
      "              umbrella        128         18      0.748      0.494      0.633      0.425\n",
      "               handbag        128         19      0.569     0.0744      0.185     0.0976\n",
      "                   tie        128          7      0.799      0.714      0.677      0.455\n",
      "              suitcase        128          4      0.639          1      0.828      0.622\n",
      "               frisbee        128          5      0.609        0.8       0.76      0.688\n",
      "                  skis        128          1      0.625          1      0.995      0.497\n",
      "             snowboard        128          7      0.703      0.714      0.764      0.506\n",
      "           sports ball        128          6      0.588      0.333      0.477      0.269\n",
      "                  kite        128         10      0.816        0.5      0.588      0.215\n",
      "          baseball bat        128          4      0.408      0.362      0.373      0.187\n",
      "        baseball glove        128          7      0.656      0.429       0.43      0.295\n",
      "            skateboard        128          5      0.759        0.6      0.599      0.446\n",
      "         tennis racket        128          7      0.741      0.414      0.502      0.342\n",
      "                bottle        128         18      0.501      0.389      0.355       0.21\n",
      "            wine glass        128         16      0.575      0.562      0.558      0.329\n",
      "                   cup        128         36      0.615      0.267      0.399      0.283\n",
      "                  fork        128          6      0.581      0.167      0.296      0.206\n",
      "                 knife        128         16      0.635      0.544      0.603      0.364\n",
      "                 spoon        128         22      0.613      0.227       0.34      0.186\n",
      "                  bowl        128         28      0.652      0.679      0.642      0.535\n",
      "                banana        128          1          0          0      0.142      0.042\n",
      "              sandwich        128          2      0.383        0.5      0.662      0.662\n",
      "                orange        128          4          1      0.357      0.995      0.666\n",
      "              broccoli        128         11      0.418      0.198      0.271      0.222\n",
      "                carrot        128         24      0.685      0.543      0.692      0.448\n",
      "               hot dog        128          2      0.652      0.956      0.828      0.796\n",
      "                 pizza        128          5      0.792          1      0.995      0.844\n",
      "                 donut        128         14      0.645          1      0.917       0.83\n",
      "                  cake        128          4      0.735          1      0.995       0.88\n",
      "                 chair        128         35      0.479      0.486      0.466      0.266\n",
      "                 couch        128          6      0.404      0.333      0.641       0.49\n",
      "          potted plant        128         14       0.69      0.643      0.729        0.5\n",
      "                   bed        128          3       0.76      0.667       0.83      0.689\n",
      "          dining table        128         13       0.46      0.615      0.496      0.395\n",
      "                toilet        128          2      0.623        0.5      0.828      0.796\n",
      "                    tv        128          2      0.408        0.5      0.695      0.656\n",
      "                laptop        128          3          1      0.341      0.764      0.602\n",
      "                 mouse        128          2          1          0     0.0483    0.00483\n",
      "                remote        128          8      0.838        0.5      0.581      0.505\n",
      "            cell phone        128          8          0          0     0.0578     0.0361\n",
      "             microwave        128          3      0.486      0.667       0.83      0.733\n",
      "                  oven        128          5      0.462        0.4      0.343      0.273\n",
      "                  sink        128          6      0.359      0.167      0.231      0.147\n",
      "          refrigerator        128          5      0.691        0.4      0.648      0.525\n",
      "                  book        128         29      0.642      0.125      0.376      0.189\n",
      "                 clock        128          9       0.81      0.778      0.895       0.74\n",
      "                  vase        128          2      0.365          1      0.828      0.795\n",
      "              scissors        128          1          1          0      0.249     0.0802\n",
      "            teddy bear        128         21      0.887      0.375      0.624       0.43\n",
      "            toothbrush        128          5       0.71      0.503      0.702      0.442\n",
      "Speed: 2.9ms preprocess, 99.9ms inference, 0.0ms loss, 3.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train3\u001b[0m\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 c:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\bus.jpg: 640x480 4 persons, 1 bus, 1 stop sign, 109.8ms\n",
      "Speed: 3.6ms preprocess, 109.8ms inference, 1.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       " obb: None\n",
       " orig_img: array([[[122, 148, 172],\n",
       "         [120, 146, 170],\n",
       "         [125, 153, 177],\n",
       "         ...,\n",
       "         [157, 170, 184],\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185]],\n",
       " \n",
       "        [[127, 153, 177],\n",
       "         [124, 150, 174],\n",
       "         [127, 155, 179],\n",
       "         ...,\n",
       "         [158, 171, 185],\n",
       "         [159, 172, 186],\n",
       "         [159, 172, 186]],\n",
       " \n",
       "        [[128, 154, 178],\n",
       "         [126, 152, 176],\n",
       "         [126, 154, 178],\n",
       "         ...,\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[185, 185, 191],\n",
       "         [182, 182, 188],\n",
       "         [179, 179, 185],\n",
       "         ...,\n",
       "         [114, 107, 112],\n",
       "         [115, 105, 111],\n",
       "         [116, 106, 112]],\n",
       " \n",
       "        [[157, 157, 163],\n",
       "         [180, 180, 186],\n",
       "         [185, 186, 190],\n",
       "         ...,\n",
       "         [107,  97, 103],\n",
       "         [102,  92,  98],\n",
       "         [108,  98, 104]],\n",
       " \n",
       "        [[112, 112, 118],\n",
       "         [160, 160, 166],\n",
       "         [169, 170, 174],\n",
       "         ...,\n",
       "         [ 99,  89,  95],\n",
       "         [ 96,  86,  92],\n",
       "         [102,  92,  98]]], dtype=uint8)\n",
       " orig_shape: (1080, 810)\n",
       " path: 'c:\\\\Users\\\\joeyw\\\\minor_logboek_aai_2023NEW\\\\deeplearning\\\\Les 3\\\\bus.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\detect\\\\train32'\n",
       " speed: {'preprocess': 3.6461353302001953, 'inference': 109.84635353088379, 'postprocess': 0.9977817535400391}]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load YOLOv8n, train it on COCO128 for 3 epochs and predict an image with it\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n.pt')  # load a pretrained YOLOv8n detection model\n",
    "model.train(data='coco128.yaml', epochs=3)  # train the model\n",
    "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7ZW58jUzK66B"
   },
   "source": [
    "## 2. Segmentation\n",
    "\n",
    "YOLOv8 _segmentation_ models use the `-seg` suffix, i.e. `yolov8n-seg.pt` and are pretrained on COCO. See [Segmentation Docs](https://docs.ultralytics.com/tasks/segment/) for full details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "WFPJIQl_L5HT"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n-seg.pt to 'yolov8n-seg.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.73M/6.73M [00:01<00:00, 6.90MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.42  Python-3.11.7 torch-2.2.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=segment, mode=train, model=yolov8n-seg.pt, data=coco128-seg.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\segment\\train\n",
      "\n",
      "Dataset 'coco128-seg.yaml' images not found , missing path 'C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco128-seg\\images\\train2017'\n",
      "Downloading https://ultralytics.com/assets/coco128-seg.zip to 'C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco128-seg.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.79M/6.79M [00:00<00:00, 13.5MB/s]\n",
      "Unzipping C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco128-seg.zip to C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco128-seg...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 263/263 [00:00<00:00, 961.50file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset download success  (2.6s), saved to \u001b[1mC:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\u001b[0m\n",
      "\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1150432  ultralytics.nn.modules.head.Segment          [80, 32, 64, [64, 128, 256]]  \n",
      "YOLOv8n-seg summary: 261 layers, 3409968 parameters, 3409952 gradients, 12.8 GFLOPs\n",
      "\n",
      "Transferred 417/417 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\segment\\train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco128-seg\\labels\\train2017... 126 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<00:00, 366.67it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco128-seg\\labels\\train2017.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco128-seg\\labels\\train2017.cache... 126 images, 2 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 128/128 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\segment\\train\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000119, momentum=0.9) with parameter groups 66 weight(decay=0.0), 77 weight(decay=0.0005), 76 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\segment\\train\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      1.057      2.479      1.423      1.141        281        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:22<00:00, 10.34s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.62s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.594      0.561      0.593      0.441      0.575      0.522      0.553      0.367\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G      1.036      2.481      1.328      1.153        173        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:29<00:00, 11.22s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.54s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.605      0.564      0.608      0.452      0.575      0.531      0.568      0.374\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   seg_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      1.124      2.575      1.377      1.162        244        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 8/8 [01:41<00:00, 12.70s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:41<00:00, 10.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.605      0.563      0.611      0.457      0.582      0.529      0.569      0.376\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.112 hours.\n",
      "Optimizer stripped from runs\\segment\\train\\weights\\last.pt, 7.1MB\n",
      "Optimizer stripped from runs\\segment\\train\\weights\\best.pt, 7.1MB\n",
      "\n",
      "Validating runs\\segment\\train\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.42  Python-3.11.7 torch-2.2.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
      "YOLOv8n-seg summary (fused): 195 layers, 3404320 parameters, 0 gradients, 12.6 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Mask(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:38<00:00,  9.64s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all        128        929      0.605      0.563      0.612      0.458      0.582      0.529       0.57      0.377\n",
      "                person        128        254      0.838      0.685       0.78      0.549      0.815      0.643      0.744      0.399\n",
      "               bicycle        128          6       0.35      0.183      0.368      0.224      0.397      0.167      0.337      0.199\n",
      "                   car        128         46      0.511      0.196      0.261       0.15      0.522      0.196      0.235     0.0969\n",
      "            motorcycle        128          5          1       0.87      0.995      0.764          1       0.83      0.995      0.524\n",
      "              airplane        128          6      0.739       0.95      0.913      0.776      0.607      0.777      0.793      0.579\n",
      "                   bus        128          7       0.65      0.714      0.721      0.618      0.653      0.714      0.721      0.613\n",
      "                 train        128          3      0.452      0.667       0.83      0.731      0.461      0.667       0.83      0.626\n",
      "                 truck        128         12      0.769      0.282      0.481       0.26      0.761      0.269       0.49      0.255\n",
      "                  boat        128          6      0.538      0.397      0.488      0.278      0.476      0.333      0.391      0.162\n",
      "         traffic light        128         14      0.642      0.214      0.214      0.144      0.433      0.143      0.158      0.145\n",
      "             stop sign        128          2          1      0.906      0.995      0.747          1        0.9      0.995      0.796\n",
      "                 bench        128          9      0.584      0.316      0.577      0.226      0.369      0.199      0.311     0.0966\n",
      "                  bird        128         16      0.868      0.822      0.956      0.679      0.875      0.812      0.956      0.461\n",
      "                   cat        128          4      0.735          1      0.995      0.821       0.74          1      0.995      0.846\n",
      "                   dog        128          9      0.557      0.667      0.825      0.656      0.563      0.667      0.777      0.539\n",
      "                 horse        128          2      0.522          1      0.995      0.615      0.266        0.5      0.557      0.217\n",
      "              elephant        128         17          1      0.869      0.924      0.712          1      0.868      0.888      0.588\n",
      "                  bear        128          1      0.621          1      0.995      0.995      0.627          1      0.995      0.995\n",
      "                 zebra        128          4       0.83          1      0.995      0.971      0.834          1      0.995      0.853\n",
      "               giraffe        128          9      0.846          1      0.995      0.709      0.757      0.889      0.876      0.503\n",
      "              backpack        128          6      0.715      0.431      0.557      0.302      0.709      0.417      0.462      0.306\n",
      "              umbrella        128         18      0.727      0.556      0.741       0.46       0.55      0.408      0.436      0.226\n",
      "               handbag        128         19      0.862      0.105      0.223      0.172      0.896      0.105      0.232      0.126\n",
      "                   tie        128          7      0.608      0.429      0.589      0.428      0.613      0.429      0.589      0.369\n",
      "              suitcase        128          4       0.66       0.75       0.87      0.715      0.675       0.75       0.87      0.574\n",
      "               frisbee        128          5      0.512        0.6      0.664        0.6      0.541        0.6      0.664      0.434\n",
      "                  skis        128          1      0.628          1      0.995      0.697      0.652          1      0.995      0.199\n",
      "             snowboard        128          7      0.533      0.714      0.737      0.533       0.44      0.571       0.41      0.196\n",
      "           sports ball        128          6      0.596      0.333      0.394      0.226      0.303      0.167      0.249      0.191\n",
      "                  kite        128         10      0.565        0.3      0.407      0.194      0.575        0.3      0.364      0.165\n",
      "          baseball bat        128          4      0.438       0.25      0.247     0.0556      0.451       0.25      0.297      0.127\n",
      "        baseball glove        128          7      0.736      0.429       0.43      0.269      0.748      0.429       0.43      0.297\n",
      "            skateboard        128          5      0.515        0.2      0.326      0.192      0.531        0.2      0.375        0.2\n",
      "         tennis racket        128          7       0.47      0.429      0.412      0.262      0.479      0.429      0.433       0.27\n",
      "                bottle        128         18      0.446      0.314      0.362      0.196      0.429      0.293      0.344      0.199\n",
      "            wine glass        128         16      0.644      0.688      0.707      0.332      0.426      0.438      0.362      0.217\n",
      "                   cup        128         36      0.638      0.306      0.376      0.288      0.646      0.306      0.371      0.256\n",
      "                  fork        128          6      0.386      0.167      0.258      0.212      0.394      0.167      0.253      0.118\n",
      "                 knife        128         16      0.703      0.444      0.572      0.405      0.706      0.438      0.467      0.337\n",
      "                 spoon        128         22      0.634      0.273      0.431      0.291      0.663      0.273      0.424      0.205\n",
      "                  bowl        128         28      0.704      0.714      0.681      0.546      0.673      0.679      0.638      0.359\n",
      "                banana        128          1       0.14          1      0.332      0.298      0.143          1      0.332      0.232\n",
      "              sandwich        128          2      0.234        0.5      0.662      0.645      0.241        0.5      0.662      0.596\n",
      "                orange        128          4          1          0      0.586      0.424          1          0      0.586      0.366\n",
      "              broccoli        128         11      0.352      0.182      0.288      0.229      0.356      0.182      0.317      0.236\n",
      "                carrot        128         24      0.595        0.5      0.589      0.404      0.576      0.453      0.586      0.354\n",
      "               hot dog        128          2      0.376          1      0.828      0.828      0.379          1      0.828      0.712\n",
      "                 pizza        128          5      0.548          1      0.962       0.79      0.551          1      0.962      0.764\n",
      "                 donut        128         14      0.634      0.991      0.939       0.88      0.633      0.986      0.939      0.771\n",
      "                  cake        128          4      0.608          1      0.995      0.945      0.613          1      0.995      0.871\n",
      "                 chair        128         35      0.431      0.486      0.439      0.222      0.466      0.514      0.429      0.186\n",
      "                 couch        128          6      0.543        0.6      0.633      0.515      0.464        0.5      0.496      0.315\n",
      "          potted plant        128         14      0.632      0.491       0.59       0.39      0.717      0.545      0.667      0.312\n",
      "                   bed        128          3      0.937          1      0.995      0.458      0.951          1      0.995      0.471\n",
      "          dining table        128         13      0.563      0.498      0.485      0.366     0.0934     0.0769      0.149     0.0838\n",
      "                toilet        128          2      0.447        0.5      0.519      0.515      0.459        0.5      0.519      0.513\n",
      "                    tv        128          2      0.563          1      0.995      0.895      0.581          1      0.995      0.846\n",
      "                laptop        128          3       0.67      0.333      0.503      0.468      0.684      0.333      0.507       0.27\n",
      "                 mouse        128          2          0          0     0.0796     0.0203          0          0     0.0247     0.0124\n",
      "                remote        128          8      0.821        0.5      0.625      0.497      0.826        0.5      0.641      0.449\n",
      "            cell phone        128          8      0.462       0.25      0.141     0.0817      0.476       0.25      0.135     0.0873\n",
      "             microwave        128          3      0.734      0.934      0.913      0.806      0.722      0.889      0.913       0.74\n",
      "                  oven        128          5      0.441        0.4      0.338      0.268      0.688        0.6      0.606       0.42\n",
      "                  sink        128          6      0.297      0.167      0.264      0.202      0.307      0.167      0.252      0.188\n",
      "          refrigerator        128          5      0.789      0.756      0.768      0.547      0.784      0.737      0.768      0.507\n",
      "                  book        128         29      0.347      0.103      0.363      0.174      0.359      0.103      0.275     0.0949\n",
      "                 clock        128          9       0.77      0.778      0.809      0.661      0.786      0.778      0.809      0.674\n",
      "                  vase        128          2      0.259          1      0.497      0.448      0.271          1      0.497      0.398\n",
      "              scissors        128          1          1          0          0          0          1          0          0          0\n",
      "            teddy bear        128         21       0.74      0.408       0.54      0.348      0.646      0.348      0.453      0.257\n",
      "            toothbrush        128          5      0.263        0.4      0.462      0.206      0.267        0.4      0.462      0.203\n",
      "Speed: 2.9ms preprocess, 221.6ms inference, 0.0ms loss, 6.8ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\segment\\train\u001b[0m\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 c:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\bus.jpg: 640x480 4 persons, 1 bus, 1 skateboard, 173.6ms\n",
      "Speed: 3.2ms preprocess, 173.6ms inference, 17.7ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: None\n",
       " masks: ultralytics.engine.results.Masks object\n",
       " names: {0: 'person', 1: 'bicycle', 2: 'car', 3: 'motorcycle', 4: 'airplane', 5: 'bus', 6: 'train', 7: 'truck', 8: 'boat', 9: 'traffic light', 10: 'fire hydrant', 11: 'stop sign', 12: 'parking meter', 13: 'bench', 14: 'bird', 15: 'cat', 16: 'dog', 17: 'horse', 18: 'sheep', 19: 'cow', 20: 'elephant', 21: 'bear', 22: 'zebra', 23: 'giraffe', 24: 'backpack', 25: 'umbrella', 26: 'handbag', 27: 'tie', 28: 'suitcase', 29: 'frisbee', 30: 'skis', 31: 'snowboard', 32: 'sports ball', 33: 'kite', 34: 'baseball bat', 35: 'baseball glove', 36: 'skateboard', 37: 'surfboard', 38: 'tennis racket', 39: 'bottle', 40: 'wine glass', 41: 'cup', 42: 'fork', 43: 'knife', 44: 'spoon', 45: 'bowl', 46: 'banana', 47: 'apple', 48: 'sandwich', 49: 'orange', 50: 'broccoli', 51: 'carrot', 52: 'hot dog', 53: 'pizza', 54: 'donut', 55: 'cake', 56: 'chair', 57: 'couch', 58: 'potted plant', 59: 'bed', 60: 'dining table', 61: 'toilet', 62: 'tv', 63: 'laptop', 64: 'mouse', 65: 'remote', 66: 'keyboard', 67: 'cell phone', 68: 'microwave', 69: 'oven', 70: 'toaster', 71: 'sink', 72: 'refrigerator', 73: 'book', 74: 'clock', 75: 'vase', 76: 'scissors', 77: 'teddy bear', 78: 'hair drier', 79: 'toothbrush'}\n",
       " obb: None\n",
       " orig_img: array([[[122, 148, 172],\n",
       "         [120, 146, 170],\n",
       "         [125, 153, 177],\n",
       "         ...,\n",
       "         [157, 170, 184],\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185]],\n",
       " \n",
       "        [[127, 153, 177],\n",
       "         [124, 150, 174],\n",
       "         [127, 155, 179],\n",
       "         ...,\n",
       "         [158, 171, 185],\n",
       "         [159, 172, 186],\n",
       "         [159, 172, 186]],\n",
       " \n",
       "        [[128, 154, 178],\n",
       "         [126, 152, 176],\n",
       "         [126, 154, 178],\n",
       "         ...,\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[185, 185, 191],\n",
       "         [182, 182, 188],\n",
       "         [179, 179, 185],\n",
       "         ...,\n",
       "         [114, 107, 112],\n",
       "         [115, 105, 111],\n",
       "         [116, 106, 112]],\n",
       " \n",
       "        [[157, 157, 163],\n",
       "         [180, 180, 186],\n",
       "         [185, 186, 190],\n",
       "         ...,\n",
       "         [107,  97, 103],\n",
       "         [102,  92,  98],\n",
       "         [108,  98, 104]],\n",
       " \n",
       "        [[112, 112, 118],\n",
       "         [160, 160, 166],\n",
       "         [169, 170, 174],\n",
       "         ...,\n",
       "         [ 99,  89,  95],\n",
       "         [ 96,  86,  92],\n",
       "         [102,  92,  98]]], dtype=uint8)\n",
       " orig_shape: (1080, 810)\n",
       " path: 'c:\\\\Users\\\\joeyw\\\\minor_logboek_aai_2023NEW\\\\deeplearning\\\\Les 3\\\\bus.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\segment\\\\train2'\n",
       " speed: {'preprocess': 3.204345703125, 'inference': 173.55608940124512, 'postprocess': 17.66061782836914}]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load YOLOv8n-seg, train it on COCO128-seg for 3 epochs and predict an image with it\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n-seg.pt')  # load a pretrained YOLOv8n segmentation model\n",
    "model.train(data='coco128-seg.yaml', epochs=3)  # train the model\n",
    "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ax3p94VNK9zR"
   },
   "source": [
    "## 3. Classification\n",
    "\n",
    "YOLOv8 _classification_ models use the `-cls` suffix, i.e. `yolov8n-cls.pt` and are pretrained on ImageNet. See [Classification Docs](https://docs.ultralytics.com/tasks/classify/) for full details.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "5q9Zu6zlL5rS"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n-cls.pt to 'yolov8n-cls.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5.30M/5.30M [00:00<00:00, 22.7MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.42  Python-3.11.7 torch-2.2.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=classify, mode=train, model=yolov8n-cls.pt, data=mnist160, epochs=3, time=None, patience=100, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\classify\\train\n",
      "\n",
      "Dataset not found , missing path C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\mnist160, attempting download...\n",
      "Downloading https://github.com/ultralytics/yolov5/releases/download/v1.0/mnist160.zip to 'C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\mnist160.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 70.0k/70.0k [00:00<00:00, 2.40MB/s]\n",
      "Unzipping C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\mnist160.zip to C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\mnist160...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 184/184 [00:00<00:00, 1332.13file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset download success  (1.5s), saved to \u001b[1mC:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\mnist160\u001b[0m\n",
      "\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\mnist160\\train... found 80 images in 10 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\mnist160\\test... found 80 images in 10 classes  \n",
      "Overriding model.yaml nc=1000 with nc=10\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    343050  ultralytics.nn.modules.head.Classify         [256, 10]                     \n",
      "YOLOv8n-cls summary: 99 layers, 1451098 parameters, 1451098 gradients, 3.4 GFLOPs\n",
      "Transferred 156/158 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\classify\\train', view at http://localhost:6006/\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\mnist160\\train... 80 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<00:00, 797.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\mnist160\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\mnist160\\test... 80 images, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 80/80 [00:00<00:00, 805.21it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\mnist160\\test.cache\n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 26 weight(decay=0.0), 27 weight(decay=0.0005), 27 bias(decay=0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 224 train, 224 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\classify\\train\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      2.308         16        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  1.91it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0875      0.538\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G      2.337         16        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.16it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  3.77it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all     0.0625      0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem       loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G       2.28         16        224: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 5/5 [00:02<00:00,  2.12it/s]\n",
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.112      0.613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.003 hours.\n",
      "Optimizer stripped from runs\\classify\\train\\weights\\last.pt, 3.0MB\n",
      "Optimizer stripped from runs\\classify\\train\\weights\\best.pt, 3.0MB\n",
      "\n",
      "Validating runs\\classify\\train\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.42  Python-3.11.7 torch-2.2.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
      "YOLOv8n-cls summary (fused): 73 layers, 1447690 parameters, 0 gradients, 3.3 GFLOPs\n",
      "WARNING  Dataset 'split=val' not found, using 'split=test' instead.\n",
      "\u001b[34m\u001b[1mtrain:\u001b[0m C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\mnist160\\train... found 80 images in 10 classes  \n",
      "\u001b[34m\u001b[1mval:\u001b[0m None...\n",
      "\u001b[34m\u001b[1mtest:\u001b[0m C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\mnist160\\test... found 80 images in 10 classes  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "               classes   top1_acc   top5_acc: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 3/3 [00:00<00:00,  4.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all      0.112      0.587\n",
      "Speed: 0.0ms preprocess, 6.2ms inference, 0.0ms loss, 0.0ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\classify\\train\u001b[0m\n",
      "Results saved to \u001b[1mruns\\classify\\train\u001b[0m\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 c:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\bus.jpg: 224x224 9 0.21, 6 0.12, 0 0.12, 8 0.11, 1 0.10, 26.6ms\n",
      "Speed: 16.5ms preprocess, 26.6ms inference, 0.0ms postprocess per image at shape (1, 3, 224, 224)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: None\n",
       " keypoints: None\n",
       " masks: None\n",
       " names: {0: '0', 1: '1', 2: '2', 3: '3', 4: '4', 5: '5', 6: '6', 7: '7', 8: '8', 9: '9'}\n",
       " obb: None\n",
       " orig_img: array([[[122, 148, 172],\n",
       "         [120, 146, 170],\n",
       "         [125, 153, 177],\n",
       "         ...,\n",
       "         [157, 170, 184],\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185]],\n",
       " \n",
       "        [[127, 153, 177],\n",
       "         [124, 150, 174],\n",
       "         [127, 155, 179],\n",
       "         ...,\n",
       "         [158, 171, 185],\n",
       "         [159, 172, 186],\n",
       "         [159, 172, 186]],\n",
       " \n",
       "        [[128, 154, 178],\n",
       "         [126, 152, 176],\n",
       "         [126, 154, 178],\n",
       "         ...,\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[185, 185, 191],\n",
       "         [182, 182, 188],\n",
       "         [179, 179, 185],\n",
       "         ...,\n",
       "         [114, 107, 112],\n",
       "         [115, 105, 111],\n",
       "         [116, 106, 112]],\n",
       " \n",
       "        [[157, 157, 163],\n",
       "         [180, 180, 186],\n",
       "         [185, 186, 190],\n",
       "         ...,\n",
       "         [107,  97, 103],\n",
       "         [102,  92,  98],\n",
       "         [108,  98, 104]],\n",
       " \n",
       "        [[112, 112, 118],\n",
       "         [160, 160, 166],\n",
       "         [169, 170, 174],\n",
       "         ...,\n",
       "         [ 99,  89,  95],\n",
       "         [ 96,  86,  92],\n",
       "         [102,  92,  98]]], dtype=uint8)\n",
       " orig_shape: (1080, 810)\n",
       " path: 'c:\\\\Users\\\\joeyw\\\\minor_logboek_aai_2023NEW\\\\deeplearning\\\\Les 3\\\\bus.jpg'\n",
       " probs: ultralytics.engine.results.Probs object\n",
       " save_dir: 'runs\\\\classify\\\\train2'\n",
       " speed: {'preprocess': 16.469478607177734, 'inference': 26.60226821899414, 'postprocess': 0.0}]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load YOLOv8n-cls, train it on mnist160 for 3 epochs and predict an image with it\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n-cls.pt')  # load a pretrained YOLOv8n classification model\n",
    "model.train(data='mnist160', epochs=3)  # train the model\n",
    "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SpIaFLiO11TG"
   },
   "source": [
    "## 4. Pose\n",
    "\n",
    "YOLOv8 _pose_ models use the `-pose` suffix, i.e. `yolov8n-pose.pt` and are pretrained on COCO Keypoints. See [Pose Docs](https://docs.ultralytics.com/tasks/pose/) for full details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "si4aKFNg19vX"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://github.com/ultralytics/assets/releases/download/v8.1.0/yolov8n-pose.pt to 'yolov8n-pose.pt'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 6.51M/6.51M [00:00<00:00, 15.8MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics YOLOv8.1.42  Python-3.11.7 torch-2.2.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=pose, mode=train, model=yolov8n-pose.pt, data=coco8-pose.yaml, epochs=3, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\pose\\train\n",
      "\n",
      "Dataset 'coco8-pose.yaml' images not found , missing path 'C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco8-pose\\images\\val'\n",
      "Downloading https://ultralytics.com/assets/coco8-pose.zip to 'C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco8-pose.zip'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 334k/334k [00:00<00:00, 21.6MB/s]\n",
      "Unzipping C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco8-pose.zip to C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco8-pose...: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 27/27 [00:00<00:00, 1002.48file/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset download success  (1.4s), saved to \u001b[1mC:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\u001b[0m\n",
      "\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1   1035934  ultralytics.nn.modules.head.Pose             [1, [17, 3], [64, 128, 256]]  \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "YOLOv8n-pose summary: 250 layers, 3295470 parameters, 3295454 gradients, 9.3 GFLOPs\n",
      "\n",
      "Transferred 397/397 items from pretrained weights\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs\\pose\\train', view at http://localhost:6006/\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco8-pose\\labels\\train... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 158.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco8-pose\\labels\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco8-pose\\labels\\val... 4 images, 0 backgrounds, 0 corrupt: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 4/4 [00:00<00:00, 185.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\datasets\\coco8-pose\\labels\\val.cache\n",
      "Plotting labels to runs\\pose\\train\\labels.jpg... \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.002, momentum=0.9) with parameter groups 63 weight(decay=0.0), 73 weight(decay=0.0005), 72 bias(decay=0.0)\n",
      "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added \n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\pose\\train\u001b[0m\n",
      "Starting training for 3 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        1/3         0G      1.474      1.812     0.3672      1.149      1.457          8        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.18s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.927      0.903      0.907      0.668      0.846        0.5      0.535      0.352\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        2/3         0G      1.507      4.205     0.4117      1.966      1.437         11        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.31s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:01<00:00,  1.09s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.927      0.911      0.907      0.677      0.845        0.5      0.535      0.362\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss  pose_loss  kobj_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "        3/3         0G      1.047      3.371     0.3244     0.8855      1.224         13        640: 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:02<00:00,  2.26s/it]\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.866      0.929      0.907      0.669      0.844        0.5      0.535      0.355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "3 epochs completed in 0.006 hours.\n",
      "Optimizer stripped from runs\\pose\\train\\weights\\last.pt, 6.8MB\n",
      "Optimizer stripped from runs\\pose\\train\\weights\\best.pt, 6.8MB\n",
      "\n",
      "Validating runs\\pose\\train\\weights\\best.pt...\n",
      "Ultralytics YOLOv8.1.42  Python-3.11.7 torch-2.2.1+cpu CPU (AMD Ryzen 7 5700U with Radeon Graphics)\n",
      "YOLOv8n-pose summary (fused): 187 layers, 3289964 parameters, 0 gradients, 9.2 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95)     Pose(P          R      mAP50  mAP50-95): 100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 1/1 [00:00<00:00,  1.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all          4         14      0.927      0.912      0.907      0.677      0.844        0.5      0.535      0.356\n",
      "Speed: 3.2ms preprocess, 160.3ms inference, 0.0ms loss, 1.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\pose\\train\u001b[0m\n",
      "\n",
      "Found https://ultralytics.com/images/bus.jpg locally at bus.jpg\n",
      "image 1/1 c:\\Users\\joeyw\\minor_logboek_aai_2023NEW\\deeplearning\\Les 3\\bus.jpg: 640x480 4 persons, 123.9ms\n",
      "Speed: 5.0ms preprocess, 123.9ms inference, 2.0ms postprocess per image at shape (1, 3, 640, 480)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[ultralytics.engine.results.Results object with attributes:\n",
       " \n",
       " boxes: ultralytics.engine.results.Boxes object\n",
       " keypoints: ultralytics.engine.results.Keypoints object\n",
       " masks: None\n",
       " names: {0: 'person'}\n",
       " obb: None\n",
       " orig_img: array([[[122, 148, 172],\n",
       "         [120, 146, 170],\n",
       "         [125, 153, 177],\n",
       "         ...,\n",
       "         [157, 170, 184],\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185]],\n",
       " \n",
       "        [[127, 153, 177],\n",
       "         [124, 150, 174],\n",
       "         [127, 155, 179],\n",
       "         ...,\n",
       "         [158, 171, 185],\n",
       "         [159, 172, 186],\n",
       "         [159, 172, 186]],\n",
       " \n",
       "        [[128, 154, 178],\n",
       "         [126, 152, 176],\n",
       "         [126, 154, 178],\n",
       "         ...,\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185],\n",
       "         [158, 171, 185]],\n",
       " \n",
       "        ...,\n",
       " \n",
       "        [[185, 185, 191],\n",
       "         [182, 182, 188],\n",
       "         [179, 179, 185],\n",
       "         ...,\n",
       "         [114, 107, 112],\n",
       "         [115, 105, 111],\n",
       "         [116, 106, 112]],\n",
       " \n",
       "        [[157, 157, 163],\n",
       "         [180, 180, 186],\n",
       "         [185, 186, 190],\n",
       "         ...,\n",
       "         [107,  97, 103],\n",
       "         [102,  92,  98],\n",
       "         [108,  98, 104]],\n",
       " \n",
       "        [[112, 112, 118],\n",
       "         [160, 160, 166],\n",
       "         [169, 170, 174],\n",
       "         ...,\n",
       "         [ 99,  89,  95],\n",
       "         [ 96,  86,  92],\n",
       "         [102,  92,  98]]], dtype=uint8)\n",
       " orig_shape: (1080, 810)\n",
       " path: 'c:\\\\Users\\\\joeyw\\\\minor_logboek_aai_2023NEW\\\\deeplearning\\\\Les 3\\\\bus.jpg'\n",
       " probs: None\n",
       " save_dir: 'runs\\\\pose\\\\train2'\n",
       " speed: {'preprocess': 5.021810531616211, 'inference': 123.9013671875, 'postprocess': 1.9965171813964844}]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load YOLOv8n-pose, train it on COCO8-pose for 3 epochs and predict an image with it\n",
    "from ultralytics import YOLO\n",
    "\n",
    "model = YOLO('yolov8n-pose.pt')  # load a pretrained YOLOv8n pose model\n",
    "model.train(data='coco8-pose.yaml', epochs=3)  # train the model\n",
    "model('https://ultralytics.com/images/bus.jpg')  # predict on an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": [
    {
     "file_id": "https://github.com/ultralytics/ultralytics/blob/main/examples/tutorial.ipynb",
     "timestamp": 1712055108696
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
