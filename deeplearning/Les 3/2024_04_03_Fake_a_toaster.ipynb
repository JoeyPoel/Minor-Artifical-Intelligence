{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to fake a toaster\n",
    "\n",
    "- Minor AAI HvA\n",
    "- Michiel Bontenbal & Maarten Post\n",
    "- Computer Vision les 4\n",
    "- Woensdag 3 april 2024\n",
    "\n",
    "Code werkt (bij mij) op in Keras 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code inspired by the blogpost: [*Machine Learning is Fun Part 8: How to Intentionally Trick Neural Networks*](https://medium.com/@ageitgey/machine-learning-is-fun-part-8-how-to-intentionally-trick-neural-networks-b55da32b7196) by Adam Geitgey."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First set up our environment and download the InceptionV3 Deep Neural Network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\joeyw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\joeyw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\joeyw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:979: The name tf.nn.fused_batch_norm is deprecated. Please use tf.compat.v1.nn.fused_batch_norm instead.\n",
      "\n",
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels.h5\n",
      "96112376/96112376 [==============================] - 9s 0us/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import PIL\n",
    "from PIL import Image\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras \n",
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.ndimage import zoom\n",
    "\n",
    "import keras.utils as image\n",
    "from keras import backend as K\n",
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "from tensorflow.python.client import device_lib\n",
    "from tensorflow.keras.applications import inception_v3\n",
    "\n",
    "# Load pre-trained image recognition model\n",
    "model = inception_v3.InceptionV3()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pillow in c:\\users\\joeyw\\appdata\\local\\programs\\python\\python311\\lib\\site-packages (10.2.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.2.1 -> 24.0\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install pillow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.15.0\n",
      "2.15.0\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "print(keras.__version__)\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/device:CPU:0']\n"
     ]
    }
   ],
   "source": [
    "#check available devices\n",
    "def get_available_devices():\n",
    "    local_device_protos = device_lib.list_local_devices()\n",
    "    return [x.name for x in local_device_protos]\n",
    "\n",
    "print(get_available_devices())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The example image from the blogpost, found using Google Image Search: \n",
    "\n",
    "![A persian cat](cat.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 3s 3s/step\n",
      "Downloading data from https://storage.googleapis.com/download.tensorflow.org/data/imagenet_class_index.json\n",
      "35363/35363 [==============================] - 0s 0us/step\n",
      "This is a Persian_cat with 88.38% confidence!\n"
     ]
    }
   ],
   "source": [
    "# Load the image file and convert it to a numpy array\n",
    "img = image.load_img(\"cat.png\", target_size=(299, 299))\n",
    "input_image = image.img_to_array(img)\n",
    "\n",
    "# Scale the image so all pixel intensities are between [-1, 1] as the model expects\n",
    "input_image /= 255.\n",
    "input_image -= 0.5\n",
    "input_image *= 2.\n",
    "\n",
    "# Add a 4th dimension for batch size (as Keras expects)\n",
    "input_image = np.expand_dims(input_image, axis=0)\n",
    "\n",
    "# Run the image through the neural network\n",
    "predictions = model.predict(input_image)\n",
    "\n",
    "# Convert the predictions into text and print them\n",
    "predicted_classes = inception_v3.decode_predictions(predictions, top=1)\n",
    "imagenet_id, name, confidence = predicted_classes[0][0]\n",
    "print(\"This is a {} with {:.4}% confidence!\".format(name, confidence * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Code to create an image that will be recognised as a toaster, by making small changes to our cat image. \n",
    "\n",
    "**Warning:** This can take over an hour on a laptop!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\joeyw\\AppData\\Local\\Temp\\ipykernel_20316\\2460153960.py:1: The name tf.disable_eager_execution is deprecated. Please use tf.compat.v1.disable_eager_execution instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\joeyw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\normalization\\batch_normalization.py:883: _colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Hacking image...\n",
      "Model's predicted likelihood that the image is a toaster: 0.00299%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003016%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003043%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003069%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003096%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003123%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003151%\n",
      "Model's predicted likelihood that the image is a toaster: 0.00318%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003209%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003239%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003271%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003302%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003334%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003367%\n",
      "Model's predicted likelihood that the image is a toaster: 0.0034%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003434%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003469%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003504%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003539%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003575%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003611%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003649%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003687%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003725%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003765%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003805%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003846%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003889%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003932%\n",
      "Model's predicted likelihood that the image is a toaster: 0.003977%\n",
      "Model's predicted likelihood that the image is a toaster: 0.004022%\n",
      "Model's predicted likelihood that the image is a toaster: 0.004068%\n",
      "Model's predicted likelihood that the image is a toaster: 0.004115%\n",
      "Model's predicted likelihood that the image is a toaster: 0.004163%\n",
      "Model's predicted likelihood that the image is a toaster: 0.004214%\n",
      "Model's predicted likelihood that the image is a toaster: 0.004267%\n",
      "Model's predicted likelihood that the image is a toaster: 0.004322%\n",
      "Model's predicted likelihood that the image is a toaster: 0.00438%\n",
      "Model's predicted likelihood that the image is a toaster: 0.004441%\n",
      "Model's predicted likelihood that the image is a toaster: 0.004504%\n",
      "Model's predicted likelihood that the image is a toaster: 0.004569%\n",
      "Model's predicted likelihood that the image is a toaster: 0.004634%\n",
      "Model's predicted likelihood that the image is a toaster: 0.004702%\n",
      "Model's predicted likelihood that the image is a toaster: 0.00477%\n",
      "Model's predicted likelihood that the image is a toaster: 0.00484%\n",
      "Model's predicted likelihood that the image is a toaster: 0.004912%\n",
      "Model's predicted likelihood that the image is a toaster: 0.004988%\n",
      "Model's predicted likelihood that the image is a toaster: 0.005065%\n",
      "Model's predicted likelihood that the image is a toaster: 0.005145%\n",
      "Model's predicted likelihood that the image is a toaster: 0.005229%\n",
      "Model's predicted likelihood that the image is a toaster: 0.005315%\n",
      "Model's predicted likelihood that the image is a toaster: 0.005405%\n",
      "Model's predicted likelihood that the image is a toaster: 0.005498%\n",
      "Model's predicted likelihood that the image is a toaster: 0.005595%\n",
      "Model's predicted likelihood that the image is a toaster: 0.005694%\n",
      "Model's predicted likelihood that the image is a toaster: 0.005797%\n",
      "Model's predicted likelihood that the image is a toaster: 0.005903%\n",
      "Model's predicted likelihood that the image is a toaster: 0.006014%\n",
      "Model's predicted likelihood that the image is a toaster: 0.006128%\n",
      "Model's predicted likelihood that the image is a toaster: 0.006246%\n",
      "Model's predicted likelihood that the image is a toaster: 0.00637%\n",
      "Model's predicted likelihood that the image is a toaster: 0.006498%\n",
      "Model's predicted likelihood that the image is a toaster: 0.006632%\n",
      "Model's predicted likelihood that the image is a toaster: 0.006771%\n",
      "Model's predicted likelihood that the image is a toaster: 0.006916%\n",
      "Model's predicted likelihood that the image is a toaster: 0.007071%\n",
      "Model's predicted likelihood that the image is a toaster: 0.007233%\n",
      "Model's predicted likelihood that the image is a toaster: 0.007402%\n",
      "Model's predicted likelihood that the image is a toaster: 0.007578%\n",
      "Model's predicted likelihood that the image is a toaster: 0.00777%\n",
      "Model's predicted likelihood that the image is a toaster: 0.007972%\n",
      "Model's predicted likelihood that the image is a toaster: 0.00818%\n",
      "Model's predicted likelihood that the image is a toaster: 0.00839%\n",
      "Model's predicted likelihood that the image is a toaster: 0.0086%\n",
      "Model's predicted likelihood that the image is a toaster: 0.008823%\n",
      "Model's predicted likelihood that the image is a toaster: 0.009046%\n",
      "Model's predicted likelihood that the image is a toaster: 0.009283%\n",
      "Model's predicted likelihood that the image is a toaster: 0.009532%\n",
      "Model's predicted likelihood that the image is a toaster: 0.009798%\n",
      "Model's predicted likelihood that the image is a toaster: 0.0101%\n",
      "Model's predicted likelihood that the image is a toaster: 0.01042%\n",
      "Model's predicted likelihood that the image is a toaster: 0.01077%\n",
      "Model's predicted likelihood that the image is a toaster: 0.01115%\n",
      "Model's predicted likelihood that the image is a toaster: 0.01157%\n",
      "Model's predicted likelihood that the image is a toaster: 0.01205%\n",
      "Model's predicted likelihood that the image is a toaster: 0.01256%\n",
      "Model's predicted likelihood that the image is a toaster: 0.01311%\n",
      "Model's predicted likelihood that the image is a toaster: 0.01371%\n",
      "Model's predicted likelihood that the image is a toaster: 0.01438%\n",
      "Model's predicted likelihood that the image is a toaster: 0.01513%\n",
      "Model's predicted likelihood that the image is a toaster: 0.01596%\n",
      "Model's predicted likelihood that the image is a toaster: 0.01698%\n",
      "Model's predicted likelihood that the image is a toaster: 0.01826%\n",
      "Model's predicted likelihood that the image is a toaster: 0.01987%\n",
      "Model's predicted likelihood that the image is a toaster: 0.02177%\n",
      "Model's predicted likelihood that the image is a toaster: 0.02422%\n",
      "Model's predicted likelihood that the image is a toaster: 0.02742%\n",
      "Model's predicted likelihood that the image is a toaster: 0.03099%\n",
      "Model's predicted likelihood that the image is a toaster: 0.03435%\n",
      "Model's predicted likelihood that the image is a toaster: 0.03822%\n",
      "Model's predicted likelihood that the image is a toaster: 0.04206%\n",
      "Model's predicted likelihood that the image is a toaster: 0.04583%\n",
      "Model's predicted likelihood that the image is a toaster: 0.04973%\n",
      "Model's predicted likelihood that the image is a toaster: 0.05379%\n",
      "Model's predicted likelihood that the image is a toaster: 0.05811%\n",
      "Model's predicted likelihood that the image is a toaster: 0.06253%\n",
      "Model's predicted likelihood that the image is a toaster: 0.06714%\n",
      "Model's predicted likelihood that the image is a toaster: 0.07221%\n",
      "Model's predicted likelihood that the image is a toaster: 0.07786%\n",
      "Model's predicted likelihood that the image is a toaster: 0.08433%\n",
      "Model's predicted likelihood that the image is a toaster: 0.09189%\n",
      "Model's predicted likelihood that the image is a toaster: 0.1004%\n",
      "Model's predicted likelihood that the image is a toaster: 0.11%\n",
      "Model's predicted likelihood that the image is a toaster: 0.1212%\n",
      "Model's predicted likelihood that the image is a toaster: 0.1342%\n",
      "Model's predicted likelihood that the image is a toaster: 0.15%\n",
      "Model's predicted likelihood that the image is a toaster: 0.1702%\n",
      "Model's predicted likelihood that the image is a toaster: 0.195%\n",
      "Model's predicted likelihood that the image is a toaster: 0.2253%\n",
      "Model's predicted likelihood that the image is a toaster: 0.2659%\n",
      "Model's predicted likelihood that the image is a toaster: 0.3197%\n",
      "Model's predicted likelihood that the image is a toaster: 0.4007%\n",
      "Model's predicted likelihood that the image is a toaster: 0.531%\n",
      "Model's predicted likelihood that the image is a toaster: 0.6897%\n",
      "Model's predicted likelihood that the image is a toaster: 0.9408%\n",
      "Model's predicted likelihood that the image is a toaster: 1.572%\n",
      "Model's predicted likelihood that the image is a toaster: 3.206%\n",
      "Model's predicted likelihood that the image is a toaster: 0.8595%\n",
      "Model's predicted likelihood that the image is a toaster: 8.882%\n",
      "Model's predicted likelihood that the image is a toaster: 5.131%\n",
      "Model's predicted likelihood that the image is a toaster: 7.734%\n",
      "Model's predicted likelihood that the image is a toaster: 8.502%\n",
      "Model's predicted likelihood that the image is a toaster: 79.74%\n",
      "Model's predicted likelihood that the image is a toaster: 40.56%\n",
      "Model's predicted likelihood that the image is a toaster: 71.21%\n",
      "Model's predicted likelihood that the image is a toaster: 70.61%\n",
      "Model's predicted likelihood that the image is a toaster: 93.32%\n"
     ]
    }
   ],
   "source": [
    "tf.compat.v1.disable_eager_execution()\n",
    "\n",
    "# Load pre-trained image recognition model\n",
    "model = inception_v3.InceptionV3()\n",
    "\n",
    "# Grab a reference to the first and last layer of the neural net\n",
    "model_input_layer = model.layers[0].input\n",
    "model_output_layer = model.layers[-1].output\n",
    "\n",
    "# Choose an ImageNet object to fake\n",
    "# The list of classes is available here: https://gist.github.com/ageitgey/4e1342c10a71981d0b491e1b8227328b\n",
    "# Class #859 is \"toaster\"\n",
    "object_type_to_fake = 859\n",
    "\n",
    "# Load the image to hack\n",
    "img = image.load_img(\"cat.png\", target_size=(299, 299))\n",
    "original_image = image.img_to_array(img)\n",
    "\n",
    "# Scale the image so all pixel intensities are between [-1, 1] as the model expects\n",
    "original_image /= 255.\n",
    "original_image -= 0.5\n",
    "original_image *= 2.\n",
    "\n",
    "# Add a 4th dimension for batch size (as Keras expects)\n",
    "original_image = np.expand_dims(original_image, axis=0)\n",
    "\n",
    "# Pre-calculate the maximum change we will allow to the image\n",
    "# We'll make sure our hacked image never goes past this so it doesn't look funny.\n",
    "# A larger number produces an image faster but risks more distortion.\n",
    "max_change_above = original_image + 0.1\n",
    "max_change_below = original_image - 0.1\n",
    "\n",
    "# Create a copy of the input image to hack on\n",
    "hacked_image = np.copy(original_image)\n",
    "\n",
    "# How much to update the hacked image in each iteration\n",
    "learning_rate = 2\n",
    "\n",
    "# Define the cost function.\n",
    "# Our 'cost' will be the likelihood our image is the target class according to the pre-trained model\n",
    "cost_function = model_output_layer[0, object_type_to_fake]\n",
    "\n",
    "# We'll ask Keras to calculate the gradient based on the input image and the currently predicted class\n",
    "# In this case, referring to \"model_input_layer\" will give us back image we are hacking.\n",
    "gradient_function = K.gradients(cost_function, model_input_layer)[0]\n",
    "\n",
    "# Create a Keras function that we can call to calculate the current cost and gradient\n",
    "grab_cost_and_gradients_from_model = K.function([model_input_layer, K.learning_phase()], [cost_function, gradient_function])\n",
    "\n",
    "cost = 0.0\n",
    "print(\"Hacking image...\")\n",
    "# In a loop, keep adjusting the hacked image slightly so that it tricks the model more and more\n",
    "# until it gets to at least 80% confidence\n",
    "while cost < 0.80:\n",
    "    # Check how close the image is to our target class and grab the gradients we\n",
    "    # can use to push it one more step in that direction.\n",
    "    # Note: It's really important to pass in '0' for the Keras learning mode here!\n",
    "    # Keras layers behave differently in prediction vs. train modes!\n",
    "    cost, gradients = grab_cost_and_gradients_from_model([hacked_image, 0])\n",
    "\n",
    "    step = gradients * learning_rate\n",
    "    \n",
    "    # print(\"Max steps: {:4}. Min steps: {:4}\".format(step.max(), step.min()))\n",
    "    \n",
    "    # Move the hacked image one step further towards fooling the model\n",
    "    hacked_image += gradients * learning_rate\n",
    "\n",
    "    # Ensure that the image doesn't ever change too much to either look funny or to become an invalid image\n",
    "    hacked_image = np.clip(hacked_image, max_change_below, max_change_above)\n",
    "\n",
    "    print(\"Model's predicted likelihood that the image is a toaster: {:.4}%\".format(cost * 100))\n",
    "\n",
    "# De-scale the image's pixels from [-1, 1] back to the [0, 255] range\n",
    "img = hacked_image[0]\n",
    "img /= 2.\n",
    "img += 0.5\n",
    "img *= 255.\n",
    "\n",
    "# Save the hacked image!\n",
    "# Resize to original size\n",
    "width = 235\n",
    "height = 177\n",
    "n_img = zoom(img, (height/299, width/299, 1))\n",
    "im = Image.fromarray(n_img.astype(np.uint8))\n",
    "im.save(\"hacked-image.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| ![The toaster](hacked-image.png) |\n",
    "|:--:|\n",
    "| *Toaster* |\n",
    "\n",
    "| ![The cat](cat.png) |\n",
    "|:--:|\n",
    "| *Cat* |"
   ]
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "python3"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "nteract": {
   "version": "0.15.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
