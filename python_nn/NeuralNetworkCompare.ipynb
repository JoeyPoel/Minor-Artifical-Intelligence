{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Comparison of Different Types of Neural Networks\n",
    "In this notebook, we'll explore and compare various types of neural networks, including dense neural networks, convolutional neural networks (CNN), recurrent neural networks (RNN), residual neural networks (ResNet), autoencoders, transformers, adversarial learning, and reinforcement learning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Dense Neural Network (DNN)\n",
    "\n",
    "### Description\n",
    "Dense Neural Networks, also known as fully connected networks, consist of layers where each neuron is connected to every neuron in the previous and subsequent layers. They are simple yet powerful for many types of tasks.\n",
    "\n",
    "### Type of Data\n",
    "DNNs are best suited for tabular data or structured data where features are independent and don't exhibit any spatial or temporal dependencies.\n",
    "\n",
    "### Use Cases\n",
    "- Classification tasks (e.g., predicting the category of an iris plant)\n",
    "- Regression tasks (e.g., predicting house prices)\n",
    "- General-purpose machine learning tasks\n",
    "\n",
    "### Training Process\n",
    "The training process involves feeding input data through the network, calculating the loss using a loss function, and optimizing the network weights using backpropagation and gradient descent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\joeyw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\backend.py:873: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\joeyw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\optimizers\\__init__.py:309: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
      "\n",
      "Epoch 1/10\n",
      "WARNING:tensorflow:From c:\\Users\\joeyw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "\n",
      "WARNING:tensorflow:From c:\\Users\\joeyw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\engine\\base_layer_utils.py:384: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "\n",
      "3/3 [==============================] - 3s 250ms/step - loss: 1.0245 - accuracy: 0.5000 - val_loss: 0.9832 - val_accuracy: 0.5417\n",
      "Epoch 2/10\n",
      "3/3 [==============================] - 0s 49ms/step - loss: 0.9213 - accuracy: 0.7396 - val_loss: 0.9011 - val_accuracy: 0.6250\n",
      "Epoch 3/10\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.8391 - accuracy: 0.8021 - val_loss: 0.8296 - val_accuracy: 0.7500\n",
      "Epoch 4/10\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.7654 - accuracy: 0.8125 - val_loss: 0.7659 - val_accuracy: 0.8750\n",
      "Epoch 5/10\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.6971 - accuracy: 0.7917 - val_loss: 0.7122 - val_accuracy: 0.9167\n",
      "Epoch 6/10\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6424 - accuracy: 0.8125 - val_loss: 0.6654 - val_accuracy: 0.9167\n",
      "Epoch 7/10\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.5959 - accuracy: 0.8229 - val_loss: 0.6235 - val_accuracy: 0.9167\n",
      "Epoch 8/10\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.5562 - accuracy: 0.8125 - val_loss: 0.5861 - val_accuracy: 0.9167\n",
      "Epoch 9/10\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5226 - accuracy: 0.8125 - val_loss: 0.5520 - val_accuracy: 0.8750\n",
      "Epoch 10/10\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4923 - accuracy: 0.8125 - val_loss: 0.5219 - val_accuracy: 0.8750\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26cd05b0f50>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load and preprocess the data\n",
    "iris = load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "input_shape = X_train.shape[1]\n",
    "num_classes = len(set(y))\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(64, activation='relu', input_shape=(input_shape,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Convolutional Neural Network (CNN)\n",
    "### Description\n",
    "Convolutional Neural Networks are specialized for processing grid-like data, such as images. They use convolutional layers to automatically detect spatial hierarchies in data.\n",
    "\n",
    "### Type of Data\n",
    "CNNs are ideal for image data, where spatial relationships between pixels are significant.\n",
    "\n",
    "### Use Cases\n",
    "- Image classification (e.g., classifying objects in CIFAR-10 images)\n",
    "- Object detection and segmentation\n",
    "- Image generation\n",
    "\n",
    "### Training Process\n",
    "Training involves convolving input data with filters, applying activation functions, and pooling operations to reduce dimensionality. The network learns to detect edges, textures, and higher-level patterns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
      "170498071/170498071 [==============================] - 7s 0us/step\n",
      "WARNING:tensorflow:From c:\\Users\\joeyw\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "\n",
      "Epoch 1/10\n",
      "1563/1563 [==============================] - 24s 15ms/step - loss: 1.4479 - accuracy: 0.4828 - val_loss: 1.1834 - val_accuracy: 0.5841\n",
      "Epoch 2/10\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 1.0933 - accuracy: 0.6198 - val_loss: 1.0239 - val_accuracy: 0.6443\n",
      "Epoch 3/10\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.9634 - accuracy: 0.6641 - val_loss: 0.9603 - val_accuracy: 0.6710\n",
      "Epoch 4/10\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.8820 - accuracy: 0.6924 - val_loss: 0.9226 - val_accuracy: 0.6819\n",
      "Epoch 5/10\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.8081 - accuracy: 0.7193 - val_loss: 0.9849 - val_accuracy: 0.6636\n",
      "Epoch 6/10\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.7522 - accuracy: 0.7389 - val_loss: 0.8887 - val_accuracy: 0.6948\n",
      "Epoch 7/10\n",
      "1563/1563 [==============================] - 22s 14ms/step - loss: 0.7033 - accuracy: 0.7555 - val_loss: 0.8925 - val_accuracy: 0.6959\n",
      "Epoch 8/10\n",
      "1563/1563 [==============================] - 21s 13ms/step - loss: 0.6642 - accuracy: 0.7674 - val_loss: 0.9714 - val_accuracy: 0.6804\n",
      "Epoch 9/10\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.6260 - accuracy: 0.7805 - val_loss: 0.9845 - val_accuracy: 0.6810\n",
      "Epoch 10/10\n",
      "1563/1563 [==============================] - 21s 14ms/step - loss: 0.5851 - accuracy: 0.7936 - val_loss: 0.9592 - val_accuracy: 0.6901\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26cd0543ad0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense\n",
    "\n",
    "# Load and preprocess the data\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "img_height, img_width = X_train.shape[1], X_train.shape[2]\n",
    "num_classes = len(set(y_train.flatten()))\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Conv2D(32, kernel_size=(3, 3), activation='relu', input_shape=(img_height, img_width, 3)),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Conv2D(64, kernel_size=(3, 3), activation='relu'),\n",
    "    MaxPooling2D(pool_size=(2, 2)),\n",
    "    Flatten(),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_data=(X_test, y_test))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Recurrent Neural Network (RNN)\n",
    "### Description\n",
    "Recurrent Neural Networks are designed to handle sequential data by maintaining a hidden state that captures information from previous time steps.\n",
    "\n",
    "### Type of Data\n",
    "RNNs are suited for sequential data such as time series, text, and any data where order matters.\n",
    "\n",
    "### Use Cases\n",
    "- Text generation and classification\n",
    "- Language translation\n",
    "- Time series forecasting\n",
    "### Training Process\n",
    "RNNs process data one step at a time, updating their hidden state. Training involves backpropagation through time (BPTT) to handle dependencies across different time steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 163s 254ms/step - loss: 0.4439 - accuracy: 0.7876 - val_loss: 0.3052 - val_accuracy: 0.8714\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 153s 244ms/step - loss: 0.2440 - accuracy: 0.9067 - val_loss: 0.2951 - val_accuracy: 0.8788\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 154s 246ms/step - loss: 0.1721 - accuracy: 0.9357 - val_loss: 0.3515 - val_accuracy: 0.8684\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 179s 286ms/step - loss: 0.1618 - accuracy: 0.9364 - val_loss: 0.5246 - val_accuracy: 0.7442\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 173s 276ms/step - loss: 0.1442 - accuracy: 0.9450 - val_loss: 0.4166 - val_accuracy: 0.8674\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 164s 262ms/step - loss: 0.0692 - accuracy: 0.9754 - val_loss: 0.5002 - val_accuracy: 0.8592\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 170s 273ms/step - loss: 0.0604 - accuracy: 0.9793 - val_loss: 0.5270 - val_accuracy: 0.8562\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 164s 262ms/step - loss: 0.0518 - accuracy: 0.9830 - val_loss: 0.5946 - val_accuracy: 0.8320\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 158s 252ms/step - loss: 0.0465 - accuracy: 0.9829 - val_loss: 0.6538 - val_accuracy: 0.8526\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 163s 260ms/step - loss: 0.0369 - accuracy: 0.9870 - val_loss: 0.7292 - val_accuracy: 0.8378\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26cd074b710>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense\n",
    "from tensorflow.keras.datasets import imdb\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "# Load and preprocess the data\n",
    "vocab_size = 10000\n",
    "max_length = 500\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "X_train = pad_sequences(X_train, maxlen=max_length)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length)\n",
    "\n",
    "embedding_dim = 32\n",
    "num_classes = 2  # Binary classification\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    LSTM(64),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(num_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Residual Neural Network (ResNet)\n",
    "### Description\n",
    "Residual Networks are deep neural networks that include skip connections to prevent the vanishing gradient problem, allowing them to train deeper networks.\n",
    "\n",
    "### Type of Data\n",
    "ResNets are typically used for image data, similar to CNNs.\n",
    "\n",
    "### Use Cases\n",
    "- Image classification (e.g., CIFAR-10)\n",
    "- Object detection and segmentation\n",
    "- Deep feature extraction\n",
    "### Training Process\n",
    "ResNets use residual blocks where the input to a block is added to its output, helping gradients flow through the network. Training involves standard convolutional layers and residual connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1250/1250 [==============================] - 32s 23ms/step - loss: 1.5532 - accuracy: 0.4335 - val_loss: 1.2212 - val_accuracy: 0.5662\n",
      "Epoch 2/10\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 1.1267 - accuracy: 0.6001 - val_loss: 1.0339 - val_accuracy: 0.6347\n",
      "Epoch 3/10\n",
      "1250/1250 [==============================] - 28s 22ms/step - loss: 0.9344 - accuracy: 0.6730 - val_loss: 0.9794 - val_accuracy: 0.6465\n",
      "Epoch 4/10\n",
      "1250/1250 [==============================] - 27s 22ms/step - loss: 0.8119 - accuracy: 0.7160 - val_loss: 0.8893 - val_accuracy: 0.6909\n",
      "Epoch 5/10\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.7049 - accuracy: 0.7524 - val_loss: 0.8811 - val_accuracy: 0.7031\n",
      "Epoch 6/10\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.6111 - accuracy: 0.7849 - val_loss: 0.8769 - val_accuracy: 0.7010\n",
      "Epoch 7/10\n",
      "1250/1250 [==============================] - 29s 24ms/step - loss: 0.5356 - accuracy: 0.8111 - val_loss: 0.9418 - val_accuracy: 0.7043\n",
      "Epoch 8/10\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.4640 - accuracy: 0.8363 - val_loss: 0.9084 - val_accuracy: 0.7173\n",
      "Epoch 9/10\n",
      "1250/1250 [==============================] - 30s 24ms/step - loss: 0.3968 - accuracy: 0.8604 - val_loss: 0.9819 - val_accuracy: 0.7066\n",
      "Epoch 10/10\n",
      "1250/1250 [==============================] - 29s 23ms/step - loss: 0.3434 - accuracy: 0.8783 - val_loss: 1.0743 - val_accuracy: 0.7041\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26cfcb684d0>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Add, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Load and preprocess the data\n",
    "(X_train, y_train), (X_test, y_test) = tf.keras.datasets.cifar10.load_data()\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "input_shape = (32, 32, 3)\n",
    "num_classes = 10\n",
    "\n",
    "# Define the model\n",
    "inputs = Input(shape=input_shape)\n",
    "x = Conv2D(32, kernel_size=(3, 3), activation='relu')(inputs)\n",
    "x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation='relu')(x)\n",
    "block_1_output = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(block_1_output)\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "block_2_output = Add()([x, block_1_output])\n",
    "\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(block_2_output)\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same')(x)\n",
    "block_3_output = Add()([x, block_2_output])\n",
    "\n",
    "x = Flatten()(block_3_output)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "outputs = Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs, outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Autoencoders\n",
    "### Description\n",
    "Autoencoders are neural networks used for unsupervised learning, particularly for dimensionality reduction and feature learning. They consist of an encoder and a decoder.\n",
    "\n",
    "### Type of Data\n",
    "Autoencoders can be used on any type of data but are particularly useful for image data and high-dimensional data.\n",
    "\n",
    "### Use Cases\n",
    "- Anomaly detection\n",
    "- Data compression\n",
    "- Noise reduction\n",
    "### Training Process\n",
    "Training involves learning to encode the input data into a lower-dimensional space and then reconstructing the original data from this encoding. The network is trained to minimize reconstruction error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "1500/1500 [==============================] - 13s 7ms/step - loss: 0.0327 - val_loss: 0.0202\n",
      "Epoch 2/10\n",
      "1500/1500 [==============================] - 10s 7ms/step - loss: 0.0176 - val_loss: 0.0158\n",
      "Epoch 3/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0144 - val_loss: 0.0135\n",
      "Epoch 4/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0126 - val_loss: 0.0119\n",
      "Epoch 5/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0112 - val_loss: 0.0111\n",
      "Epoch 6/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0104 - val_loss: 0.0103\n",
      "Epoch 7/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0099 - val_loss: 0.0098\n",
      "Epoch 8/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0094 - val_loss: 0.0095\n",
      "Epoch 9/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0091 - val_loss: 0.0091\n",
      "Epoch 10/10\n",
      "1500/1500 [==============================] - 9s 6ms/step - loss: 0.0088 - val_loss: 0.0089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26cd926e050>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Flatten, Reshape\n",
    "from tensorflow.keras.datasets import mnist\n",
    "\n",
    "# Load and preprocess the data\n",
    "(X_train, _), (X_test, _) = mnist.load_data()\n",
    "X_train = X_train / 255.0\n",
    "X_test = X_test / 255.0\n",
    "X_train = X_train.reshape(-1, 784)\n",
    "X_test = X_test.reshape(-1, 784)\n",
    "\n",
    "input_shape = 784\n",
    "\n",
    "# Define the model\n",
    "model = Sequential([\n",
    "    Dense(128, activation='relu', input_shape=(input_shape,)),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(64, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "    Dense(input_shape, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, X_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Transformers\n",
    "### Description\n",
    "Transformers are a type of neural network architecture designed to handle sequential data but without relying on recurrence (unlike RNNs). They use self-attention mechanisms to weigh the influence of different parts of the input data, allowing them to capture long-range dependencies effectively.\n",
    "\n",
    "### Type of Data\n",
    "Transformers are used primarily for text and sequential data but have been adapted for other types of data, including images (e.g., Vision Transformers).\n",
    "\n",
    "### Use Cases\n",
    "- Natural language processing (NLP) tasks like translation, summarization, and sentiment analysis\n",
    "- Text generation (e.g., GPT-3, BERT)\n",
    "- Image classification and generation (Vision Transformers)\n",
    "### Training Process\n",
    "Training involves learning attention weights that highlight the importance of different words (or tokens) in a sequence. Transformers are trained using large datasets and optimized using gradient descent methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "625/625 [==============================] - 108s 168ms/step - loss: 0.4072 - accuracy: 0.7946 - val_loss: 0.2922 - val_accuracy: 0.8786\n",
      "Epoch 2/10\n",
      "625/625 [==============================] - 104s 166ms/step - loss: 0.2141 - accuracy: 0.9155 - val_loss: 0.2829 - val_accuracy: 0.8852\n",
      "Epoch 3/10\n",
      "625/625 [==============================] - 98s 157ms/step - loss: 0.1570 - accuracy: 0.9390 - val_loss: 0.3110 - val_accuracy: 0.8866\n",
      "Epoch 4/10\n",
      "625/625 [==============================] - 100s 160ms/step - loss: 0.1182 - accuracy: 0.9567 - val_loss: 0.3396 - val_accuracy: 0.8820\n",
      "Epoch 5/10\n",
      "625/625 [==============================] - 100s 160ms/step - loss: 0.0835 - accuracy: 0.9698 - val_loss: 0.5830 - val_accuracy: 0.8662\n",
      "Epoch 6/10\n",
      "625/625 [==============================] - 101s 161ms/step - loss: 0.0661 - accuracy: 0.9754 - val_loss: 0.5233 - val_accuracy: 0.8726\n",
      "Epoch 7/10\n",
      "625/625 [==============================] - 101s 162ms/step - loss: 0.0490 - accuracy: 0.9829 - val_loss: 0.6721 - val_accuracy: 0.8638\n",
      "Epoch 8/10\n",
      "625/625 [==============================] - 100s 161ms/step - loss: 0.0364 - accuracy: 0.9876 - val_loss: 0.6954 - val_accuracy: 0.8676\n",
      "Epoch 9/10\n",
      "625/625 [==============================] - 108s 172ms/step - loss: 0.0308 - accuracy: 0.9895 - val_loss: 0.8661 - val_accuracy: 0.8558\n",
      "Epoch 10/10\n",
      "625/625 [==============================] - 109s 174ms/step - loss: 0.0253 - accuracy: 0.9916 - val_loss: 0.9935 - val_accuracy: 0.8608\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x26cec435210>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Dense, Embedding, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.datasets import imdb\n",
    "\n",
    "# Load and preprocess the data\n",
    "vocab_size = 10000\n",
    "max_length = 500\n",
    "(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=vocab_size)\n",
    "X_train = pad_sequences(X_train, maxlen=max_length)\n",
    "X_test = pad_sequences(X_test, maxlen=max_length)\n",
    "\n",
    "embedding_dim = 32\n",
    "num_classes = 2\n",
    "\n",
    "# Define the model\n",
    "inputs = Input(shape=(max_length,))\n",
    "embedding_layer = Embedding(input_dim=vocab_size, output_dim=embedding_dim)(inputs)\n",
    "transformer_block = tf.keras.layers.MultiHeadAttention(num_heads=2, key_dim=embedding_dim)(embedding_layer, embedding_layer)\n",
    "# Flatten the output of the transformer block if necessary\n",
    "flattened_layer = tf.keras.layers.Flatten()(transformer_block)\n",
    "dropout_layer = Dropout(0.1)(flattened_layer)\n",
    "dense_layer = Dense(64, activation='relu')(dropout_layer)\n",
    "outputs = Dense(num_classes, activation='softmax')(dense_layer)\n",
    "\n",
    "model = Model(inputs=inputs, outputs=outputs)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss='sparse_categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=32, validation_split=0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Generative Adversarial Networks (GANs)\n",
    "### Description\n",
    "Generative Adversarial Networks consist of two neural networks, a generator and a discriminator, that compete against each other. The generator creates data, while the discriminator tries to distinguish between real and generated data.\n",
    "\n",
    "### Type of Data\n",
    "GANs are primarily used with image data but can be applied to any data type where generating realistic data is valuable.\n",
    "\n",
    "### Use Cases\n",
    "- Image generation\n",
    "- Data augmentation\n",
    "- Creative applications (e.g., art and music generation)\n",
    "### Training Process\n",
    "The training process alternates between training the discriminator to distinguish real from fake data and training the generator to produce data that can fool the discriminator. This adversarial process helps the generator produce realistic data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, D Loss: [0.71170622 0.46875   ], G Loss: 0.9469071626663208\n",
      "Epoch 1000, D Loss: [0.27582335 0.921875  ], G Loss: 2.6114182472229004\n",
      "Epoch 2000, D Loss: [0.27922937 0.90625   ], G Loss: 2.7924535274505615\n",
      "Epoch 3000, D Loss: [0.44835685 0.765625  ], G Loss: 3.3652374744415283\n",
      "Epoch 4000, D Loss: [0.27148907 0.890625  ], G Loss: 3.258960247039795\n",
      "Epoch 5000, D Loss: [0.30840922 0.859375  ], G Loss: 3.7118265628814697\n",
      "Epoch 6000, D Loss: [0.25601084 0.90625   ], G Loss: 3.7888922691345215\n",
      "Epoch 7000, D Loss: [0.17177273 0.9375    ], G Loss: 4.360065937042236\n",
      "Epoch 8000, D Loss: [0.24589257 0.90625   ], G Loss: 3.502284526824951\n",
      "Epoch 9000, D Loss: [0.41012922 0.875     ], G Loss: 4.5679121017456055\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "# Importing necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, LeakyReLU, Reshape, Flatten, Input\n",
    "from tensorflow.keras.models import Model\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# Suppress TensorFlow logs\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "# Load and preprocess the data\n",
    "(X_train, _), (_, _) = tf.keras.datasets.mnist.load_data()\n",
    "X_train = X_train / 255.0\n",
    "X_train = X_train.reshape(-1, 28, 28)  # Ensure the shape is (number of samples, 28, 28)\n",
    "\n",
    "noise_dim = 100\n",
    "\n",
    "# Define the generator model\n",
    "generator = Sequential([\n",
    "    Dense(128, input_shape=(noise_dim,)),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(784, activation='tanh'),\n",
    "    Reshape((28, 28))  # Output shape should be (28, 28)\n",
    "])\n",
    "\n",
    "# Define the discriminator model\n",
    "discriminator = Sequential([\n",
    "    Flatten(input_shape=(28, 28)),\n",
    "    Dense(128),\n",
    "    LeakyReLU(alpha=0.2),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "# Compile the discriminator\n",
    "discriminator.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Combine generator and discriminator to make GAN\n",
    "discriminator.trainable = False\n",
    "gan_input = Input(shape=(noise_dim,))\n",
    "x = generator(gan_input)\n",
    "gan_output = discriminator(x)\n",
    "gan = Model(gan_input, gan_output)\n",
    "\n",
    "# Compile GAN\n",
    "gan.compile(optimizer='adam', loss='binary_crossentropy')\n",
    "\n",
    "# Training GAN\n",
    "batch_size = 32\n",
    "epochs = 10000\n",
    "for epoch in range(epochs):\n",
    "    # Train discriminator\n",
    "    idx = np.random.randint(0, X_train.shape[0], batch_size)\n",
    "    real_images = X_train[idx]\n",
    "    noise = np.random.normal(0, 1, (batch_size, noise_dim))\n",
    "    fake_images = generator.predict(noise, verbose=0)  # Suppress verbose output\n",
    "    \n",
    "    real_labels = np.ones((batch_size, 1))\n",
    "    fake_labels = np.zeros((batch_size, 1))\n",
    "    \n",
    "    d_loss_real = discriminator.train_on_batch(real_images, real_labels)\n",
    "    d_loss_fake = discriminator.train_on_batch(fake_images, fake_labels)\n",
    "    \n",
    "    # Train generator\n",
    "    noise = np.random.normal(0, 1, (batch_size, noise_dim))\n",
    "    valid_y = np.ones((batch_size, 1))\n",
    "    g_loss = gan.train_on_batch(noise, valid_y)\n",
    "    \n",
    "    if epoch % 1000 == 0:\n",
    "        print(f\"Epoch {epoch}, D Loss: {0.5 * np.add(d_loss_real, d_loss_fake)}, G Loss: {g_loss}\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Reinforcement Learning (RL)\n",
    "### Description\n",
    "Reinforcement Learning (RL) is a type of machine learning where an agent learns to make decisions by interacting with an environment. The agent takes actions to maximize cumulative rewards over time. Unlike supervised learning, RL does not require labeled input/output pairs and relies on trial and error to discover the best actions.\n",
    "\n",
    "### Type of Data\n",
    "- Data Type: Interaction data between the agent and the environment.\n",
    "- Data Shape: Typically involves state-action-reward sequences, where each sequence represents the state of the environment, the action taken by the agent, and the reward received.\n",
    "### Use Cases\n",
    "- Game playing (e.g., AlphaGo, OpenAI's Dota 2 bot)\n",
    "- Robotics (e.g., robot navigation, manipulation tasks)\n",
    "- Self-driving cars (e.g., decision-making, path planning)\n",
    "- Optimization problems (e.g., resource management, traffic control)\n",
    "### Training Process\n",
    "1. Initialization: The agent initializes its policy (strategy) and value function (expected reward).\n",
    "2. Interaction: The agent interacts with the environment by taking actions and observing the resulting state and reward.\n",
    "3. Policy Update: Based on the observed reward and state transitions, the agent updates its policy to improve future actions.\n",
    "4. Exploration vs. Exploitation: The agent balances exploration (trying new actions) and exploitation (using known actions that yield high rewards).\n",
    "The training continues until the agent's performance converges or improves to a satisfactory level."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.1 Environment Setup\n",
    "First, let's define a simple environment. We'll create a grid world where an agent has to navigate from a starting position to a goal position while avoiding obstacles. The agent can move up, down, left, or right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GridWorld:\n",
    "    def __init__(self, width, height, start, goal, obstacles):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.start = start\n",
    "        self.goal = goal\n",
    "        self.obstacles = obstacles\n",
    "        self.agent_position = start\n",
    "\n",
    "    def move_agent(self, action):\n",
    "        x, y = self.agent_position\n",
    "        if action == \"UP\" and y > 0:\n",
    "            self.agent_position = (x, y - 1)\n",
    "        elif action == \"DOWN\" and y < self.height - 1:\n",
    "            self.agent_position = (x, y + 1)\n",
    "        elif action == \"LEFT\" and x > 0:\n",
    "            self.agent_position = (x - 1, y)\n",
    "        elif action == \"RIGHT\" and x < self.width - 1:\n",
    "            self.agent_position = (x + 1, y)\n",
    "\n",
    "    def is_goal_reached(self):\n",
    "        return self.agent_position == self.goal\n",
    "\n",
    "    def is_obstacle(self, position):\n",
    "        return position in self.obstacles\n",
    "\n",
    "    def reset(self):\n",
    "        self.agent_position = self.start\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.2 Q-Learning Algorithm\n",
    "Now, let's implement the Q-learning algorithm to train an agent to navigate the grid world."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class QLearningAgent:\n",
    "    def __init__(self, num_actions, epsilon=0.1, alpha=0.1, gamma=0.9):\n",
    "        self.num_actions = num_actions\n",
    "        self.epsilon = epsilon\n",
    "        self.alpha = alpha\n",
    "        self.gamma = gamma\n",
    "        self.q_table = np.zeros((num_actions, num_actions))\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if np.random.uniform(0, 1) < self.epsilon:\n",
    "            return np.random.randint(self.num_actions)\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state])\n",
    "\n",
    "\n",
    "    def update_q_table(self, state, action, reward, next_state):\n",
    "        best_next_action = np.argmax(self.q_table[next_state])\n",
    "        td_target = reward + self.gamma * self.q_table[next_state, best_next_action]\n",
    "        td_error = td_target - self.q_table[state, action]\n",
    "        self.q_table[state, action] += self.alpha * td_error\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.3 Training the Agent\n",
    "Now, let's train the agent to navigate the grid world using Q-learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 26\u001b[0m\n\u001b[0;32m     23\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m env\u001b[38;5;241m.\u001b[39mis_obstacle(next_state) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0\u001b[39m\n\u001b[0;32m     24\u001b[0m done \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mis_goal_reached()\n\u001b[1;32m---> 26\u001b[0m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mupdate_q_table\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreward\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnext_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     27\u001b[0m total_reward \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m reward\n\u001b[0;32m     28\u001b[0m state \u001b[38;5;241m=\u001b[39m next_state\n",
      "Cell \u001b[1;32mIn[22], line 21\u001b[0m, in \u001b[0;36mQLearningAgent.update_q_table\u001b[1;34m(self, state, action, reward, next_state)\u001b[0m\n\u001b[0;32m     19\u001b[0m best_next_action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_table[next_state])\n\u001b[0;32m     20\u001b[0m td_target \u001b[38;5;241m=\u001b[39m reward \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgamma \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_table[next_state, best_next_action]\n\u001b[1;32m---> 21\u001b[0m td_error \u001b[38;5;241m=\u001b[39m td_target \u001b[38;5;241m-\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mq_table\u001b[49m\u001b[43m[\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_table[state, action] \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39malpha \u001b[38;5;241m*\u001b[39m td_error\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Define the environment\n",
    "width = 5\n",
    "height = 5\n",
    "start = (0, 0)\n",
    "goal = (4, 4)\n",
    "obstacles = [(1, 1), (2, 2), (3, 3)]\n",
    "env = GridWorld(width, height, start, goal, obstacles)\n",
    "\n",
    "# Define the agent\n",
    "num_actions = 4  # Up, Down, Left, Right\n",
    "agent = QLearningAgent(num_actions)\n",
    "\n",
    "# Training loop\n",
    "num_episodes = 10\n",
    "for episode in range(num_episodes):\n",
    "    state = env.start\n",
    "    done = False\n",
    "    total_reward = 0\n",
    "\n",
    "    while not done:\n",
    "        action = agent.choose_action(state)\n",
    "        next_state = env.agent_position\n",
    "        reward = -1 if env.is_obstacle(next_state) else 0\n",
    "        done = env.is_goal_reached()\n",
    "\n",
    "        agent.update_q_table(state, action, reward, next_state)\n",
    "        total_reward += reward\n",
    "        state = next_state\n",
    "\n",
    "    env.reset()\n",
    "\n",
    "    print(f\"Episode {episode + 1}: Total Reward = {total_reward}\")\n",
    "\n",
    "print(\"Training complete.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.4 Testing the Trained Agent\n",
    "Now, let's test the trained agent in the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing loop\n",
    "state = env.start\n",
    "done = False\n",
    "\n",
    "while not done:\n",
    "    action = agent.choose_action(state)\n",
    "    env.move_agent([\"UP\", \"DOWN\", \"LEFT\", \"RIGHT\"][action])\n",
    "    done = env.is_goal_reached()\n",
    "    print(f\"Agent moved to position: {env.agent_position}\")\n",
    "\n",
    "print(\"Goal reached!\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
