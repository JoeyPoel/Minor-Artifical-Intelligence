{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Notebook for Optimizing GPU, Cloud, and Real-Time Usage\n",
    "## Objective:\n",
    "This notebook aims to demonstrate techniques for optimizing the usage of GPU, cloud resources, and achieving real-time processing for various tasks. It will cover practical examples and implementations to help users understand and apply optimization strategies effectively.\n",
    "\n",
    "### Table of Contents:\n",
    "Introduction to Optimization\n",
    "Optimizing GPU Usage\n",
    "Leveraging Cloud Resources\n",
    "Real-Time Processing\n",
    "Case Studies\n",
    "Conclusion\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction to Optimization\n",
    "Overview of GPU, Cloud, and Real-Time Computing\n",
    "\n",
    "Importance of Optimization in Modern Computing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Optimizing GPU Usage\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'cupy'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcupy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mcp\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Create random data\u001b[39;00m\n\u001b[0;32m      5\u001b[0m n \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1000000\u001b[39m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'cupy'"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "\n",
    "# Create random data\n",
    "n = 1000000\n",
    "x_cpu = np.random.rand(n)\n",
    "x_gpu = cp.random.rand(n)\n",
    "\n",
    "# CPU computation\n",
    "def cpu_operation(x):\n",
    "    return np.sin(x)\n",
    "\n",
    "%timeit cpu_operation(x_cpu)\n",
    "\n",
    "# GPU computation\n",
    "x_gpu = cp.asarray(x_cpu)\n",
    "def gpu_operation(x):\n",
    "    return cp.sin(x)\n",
    "\n",
    "%timeit gpu_operation(x_gpu)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Memory Optimization Techniques\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Get size of array in bytes\n",
    "def get_size(array):\n",
    "    return sys.getsizeof(array)\n",
    "\n",
    "# Example array\n",
    "array = np.zeros((1000, 1000))\n",
    "print(\"Array size:\", get_size(array), \"bytes\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Profiling and Performance Analysis\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using NVIDIA Nsight Systems\n",
    "# Profile your CUDA code to identify bottlenecks and optimize performance\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Leveraging Cloud Resources\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example using AWS SDK to deploy and manage cloud resources\n",
    "import boto3\n",
    "\n",
    "# Create an S3 client\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# List buckets\n",
    "response = s3.list_buckets()\n",
    "buckets = [bucket['Name'] for bucket in response['Buckets']]\n",
    "print(\"Buckets:\", buckets)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizing Cost and Performance in Cloud Environments\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from numba import cuda\n",
    "import time\n",
    "\n",
    "# CUDA kernel\n",
    "@cuda.jit\n",
    "def my_kernel(io_array):\n",
    "    # Thread index\n",
    "    tx = cuda.threadIdx.x\n",
    "    ty = cuda.blockIdx.x\n",
    "    bw = cuda.blockDim.x\n",
    "    pos = tx + ty * bw\n",
    "    \n",
    "    # Do the computation\n",
    "    if pos < io_array.size:\n",
    "        io_array[pos] *= 2\n",
    "\n",
    "def main():\n",
    "    # Array size and shape\n",
    "    array_size = 10000000\n",
    "    shape = (1000, 10000)\n",
    "    \n",
    "    # Initialize input array\n",
    "    input_array = np.ones(array_size).astype(np.float32)\n",
    "    \n",
    "    # Allocate memory on GPU\n",
    "    d_input_array = cuda.to_device(input_array)\n",
    "    \n",
    "    # Start profiling\n",
    "    start_time = time.time()\n",
    "    \n",
    "    # Define block and grid dimensions\n",
    "    threads_per_block = 256\n",
    "    blocks_per_grid = (array_size + (threads_per_block - 1)) // threads_per_block\n",
    "    \n",
    "    # Launch the kernel\n",
    "    my_kernel[blocks_per_grid, threads_per_block](d_input_array)\n",
    "    \n",
    "    # Copy the result back to host\n",
    "    output_array = d_input_array.copy_to_host()\n",
    "    \n",
    "    # End profiling\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Calculate elapsed time\n",
    "    elapsed_time = end_time - start_time\n",
    "    print(\"Elapsed time: \", elapsed_time, \" seconds\")\n",
    "    \n",
    "    return output_array\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    output_array = main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Auto-scaling and Load Balancing Strategies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "\n",
    "# Initialize AWS clients\n",
    "ec2_client = boto3.client('ec2')\n",
    "autoscaling_client = boto3.client('autoscaling')\n",
    "elb_client = boto3.client('elbv2')\n",
    "\n",
    "# Create a launch configuration\n",
    "def create_launch_configuration():\n",
    "    response = autoscaling_client.create_launch_configuration(\n",
    "        LaunchConfigurationName='my-launch-config',\n",
    "        ImageId='ami-12345678',  # Replace with your AMI ID\n",
    "        InstanceType='t2.micro',\n",
    "        KeyName='my-key-pair',\n",
    "        SecurityGroups=['my-security-group'],\n",
    "        UserData='''#!/bin/bash\n",
    "                    yum update -y\n",
    "                    yum install -y httpd\n",
    "                    systemctl start httpd\n",
    "                    ''',\n",
    "        InstanceMonitoring={'Enabled': True}\n",
    "    )\n",
    "    print(\"Launch configuration created successfully.\")\n",
    "\n",
    "# Create an auto-scaling group\n",
    "def create_auto_scaling_group():\n",
    "    response = autoscaling_client.create_auto_scaling_group(\n",
    "        AutoScalingGroupName='my-auto-scaling-group',\n",
    "        LaunchConfigurationName='my-launch-config',\n",
    "        MinSize=1,\n",
    "        MaxSize=10,\n",
    "        DesiredCapacity=2,\n",
    "        AvailabilityZones=['us-west-2a'],  # Replace with your desired availability zone\n",
    "        LoadBalancerNames=['my-load-balancer'],  # Attach to existing load balancer\n",
    "        HealthCheckType='ELB',\n",
    "        HealthCheckGracePeriod=300\n",
    "    )\n",
    "    print(\"Auto-scaling group created successfully.\")\n",
    "\n",
    "# Create a load balancer\n",
    "def create_load_balancer():\n",
    "    response = elb_client.create_load_balancer(\n",
    "        Name='my-load-balancer',\n",
    "        Subnets=['subnet-12345678'],  # Replace with your subnet IDs\n",
    "        SecurityGroups=['sg-12345678'],  # Replace with your security group IDs\n",
    "        Scheme='internet-facing',\n",
    "        Type='application',\n",
    "        IpAddressType='ipv4'\n",
    "    )\n",
    "    print(\"Load balancer created successfully.\")\n",
    "\n",
    "# Main function to execute creation of resources\n",
    "def main():\n",
    "    create_launch_configuration()\n",
    "    create_auto_scaling_group()\n",
    "    create_load_balancer()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Real-Time Processing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of implementing real-time data processing with Apache Kafka\n",
    "from kafka import KafkaConsumer\n",
    "\n",
    "consumer = KafkaConsumer('my-topic',\n",
    "                         group_id='my-group',\n",
    "                         bootstrap_servers=['localhost:9092'])\n",
    "for message in consumer:\n",
    "    print (\"%s:%d:%d: key=%s value=%s\" % (message.topic, message.partition,\n",
    "                                           message.offset, message.key,\n",
    "                                           message.value))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Techniques for Achieving Low Latency Processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of using asynchronous programming with asyncio for low latency processing\n",
    "import asyncio\n",
    "\n",
    "async def main():\n",
    "    await asyncio.sleep(1)\n",
    "    print('Hello')\n",
    "\n",
    "asyncio.run(main())\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing Real-Time Applications\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of a real-time dashboard using Dash\n",
    "import dash\n",
    "import dash_core_components as dcc\n",
    "import dash_html_components as html\n",
    "import plotly.graph_objs as go\n",
    "from dash.dependencies import Input, Output\n",
    "\n",
    "app = dash.Dash()\n",
    "\n",
    "app.layout = html.Div([\n",
    "    dcc.Graph(id='live-update-graph'),\n",
    "    dcc.Interval(\n",
    "        id='interval-component',\n",
    "        interval=1*1000,  # in milliseconds\n",
    "        n_intervals=0\n",
    "    )\n",
    "])\n",
    "\n",
    "@app.callback(Output('live-update-graph', 'figure'),\n",
    "              [Input('interval-component', 'n_intervals')])\n",
    "def update_graph_live(n):\n",
    "    # Get data\n",
    "    x_data = [1, 2, 3, 4, 5]\n",
    "    y_data = [10, 20, 15, 25, 30]\n",
    "\n",
    "    # Create graph\n",
    "    fig = go.Figure()\n",
    "    fig.add_trace(go.Scatter(x=x_data, y=y_data, mode='lines+markers'))\n",
    "\n",
    "    return fig\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(debug=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Case Studies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cupy as cp\n",
    "import cv2\n",
    "import time\n",
    "\n",
    "# Load image\n",
    "image = cv2.imread('image.jpg', cv2.IMREAD_COLOR)\n",
    "height, width, channels = image.shape\n",
    "\n",
    "# Convert image to grayscale\n",
    "gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# CPU processing\n",
    "start_time_cpu = time.time()\n",
    "for i in range(1000):\n",
    "    blurred_image_cpu = cv2.GaussianBlur(gray_image, (5, 5), 0)\n",
    "end_time_cpu = time.time()\n",
    "cpu_time = end_time_cpu - start_time_cpu\n",
    "\n",
    "# GPU processing\n",
    "gray_image_gpu = cp.asarray(gray_image)\n",
    "start_time_gpu = time.time()\n",
    "for i in range(1000):\n",
    "    blurred_image_gpu = cp.asnumpy(cp.asnumpy(cp.convolve2d(gray_image_gpu, cp.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]], dtype=np.float32), mode='same')))\n",
    "end_time_gpu = time.time()\n",
    "gpu_time = end_time_gpu - start_time_gpu\n",
    "\n",
    "print(\"CPU Time:\", cpu_time, \"seconds\")\n",
    "print(\"GPU Time:\", gpu_time, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Conclusion\n",
    "Summary of Key Optimization Techniques\n",
    "\n",
    "Future Trends in GPU, Cloud, and Real-Time Computing\n",
    "\n",
    "### Tools and Technologies:\n",
    "- Programming Languages: Python, CUDA C/C++, Java (for real-time processing)\n",
    "- Libraries and Frameworks: CUDA Toolkit, TensorFlow, PyTorch, Apache Spark, AWS SDK, Azure SDK, Google Cloud SDK\n",
    "- Tools: NVIDIA Nsight, AWS Management Console, Azure Portal, Google Cloud Console\n",
    "### References:\n",
    "- NVIDIA Developer Documentation: https://developer.nvidia.com/cuda-zone\n",
    "- AWS Documentation: https://docs.aws.amazon.com/\n",
    "- Azure Documentation: https://docs.microsoft.com/en-us/azure/\n",
    "- Google Cloud Documentation: https://cloud.google.com/docs\n",
    "- Real-Time Systems by Jane W. S. Liu\n",
    "- CUDA Programming Guide\n",
    "### Notebook Setup:\n",
    "1. Ensure CUDA Toolkit and appropriate GPU drivers are installed for GPU optimization.\n",
    "2. Set up accounts and access to cloud platforms (AWS, Azure, Google Cloud) for cloud optimization.\n",
    "3. Install necessary libraries and frameworks for real-time processing."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
