{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Optimizing with GPU, Cloud, and Real-time Processing\n",
    "## Optimizing applications is essential for enhancing performance and efficiency. This can be achieved by leveraging GPUs, cloud services, and real-time processing. In this notebook, we will briefly discuss these methods and how they can be applied to optimize performance.\n",
    "\n",
    "## Table of Contents\n",
    "- Introduction\n",
    "- Using GPUs\n",
    "- Cloud Services\n",
    "- Real-time Processing\n",
    "- Conclusion\n",
    "## 1. Introduction\n",
    "Application optimization is crucial in an era where large amounts of data need to be processed quickly and efficiently. Traditional CPUs can sometimes fall short when performing intensive tasks such as machine learning, image processing, and data analysis. This is where GPUs, cloud computing, and real-time processing come into play. These technologies can significantly enhance performance and increase scalability.\n",
    "\n",
    "## 2. Using GPUs\n",
    "GPUs (Graphics Processing Units) are designed to enable parallel processing, making them ideal for performing complex calculations in a short amount of time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num GPUs Available:  0\n",
      "GPUs:  []\n",
      "No GPU found. Please check your GPU installation.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import time\n",
    "\n",
    "# Check GPU availability\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "print(\"Num GPUs Available: \", len(gpus))\n",
    "print(\"GPUs: \", gpus)\n",
    "\n",
    "if len(gpus) == 0:\n",
    "    print(\"No GPU found. Please check your GPU installation.\")\n",
    "else:\n",
    "    # Dummy data for demonstration\n",
    "    data = tf.random.normal([10000, 10000])\n",
    "\n",
    "    # CPU computation\n",
    "    start_cpu = time.time()\n",
    "    with tf.device('/CPU:0'):\n",
    "        result_cpu = tf.linalg.matmul(data, data)\n",
    "    end_cpu = time.time()\n",
    "    print(f\"CPU computation time: {end_cpu - start_cpu} seconds\")\n",
    "\n",
    "    # GPU computation\n",
    "    try:\n",
    "        start_gpu = time.time()\n",
    "        with tf.device('/GPU:0'):\n",
    "            result_gpu = tf.linalg.matmul(data, data)\n",
    "        end_gpu = time.time()\n",
    "        print(f\"GPU computation time: {end_gpu - start_gpu} seconds\")\n",
    "    except RuntimeError as e:\n",
    "        print(\"Error during GPU computation: \", e)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "GPUs can be significantly faster than CPUs for parallel tasks such as matrix multiplication, as illustrated in the code above.\n",
    "\n",
    "## 3. Cloud Services\n",
    "Cloud services offer scalability and flexibility for data storage and processing. By utilizing cloud computing, resources can be dynamically allocated based on demand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
      "\u001b[1m11490434/11490434\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\joeyw\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step - accuracy: 0.8570 - loss: 0.4931\n",
      "Epoch 2/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9556 - loss: 0.1515\n",
      "Epoch 3/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9672 - loss: 0.1084\n",
      "Epoch 4/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9750 - loss: 0.0850\n",
      "Epoch 5/5\n",
      "\u001b[1m1875/1875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.9785 - loss: 0.0687\n",
      "Training time: 16.975170612335205 seconds\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 963us/step - accuracy: 0.9734 - loss: 0.0905\n",
      "Test accuracy: 0.9782000184059143\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import mnist\n",
    "import time\n",
    "\n",
    "# Load dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "# Define the model\n",
    "model = tf.keras.models.Sequential([\n",
    "    tf.keras.layers.Flatten(input_shape=(28, 28)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dropout(0.2),\n",
    "    tf.keras.layers.Dense(10)\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "start_time = time.time()\n",
    "model.fit(x_train, y_train, epochs=5)\n",
    "end_time = time.time()\n",
    "\n",
    "print(f\"Training time: {end_time - start_time} seconds\")\n",
    "\n",
    "# Evaluate the model\n",
    "test_loss, test_acc = model.evaluate(x_test, y_test)\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With services like Amazon S3, files can be easily stored and retrieved, simplifying data storage and distribution.\n",
    "\n",
    "## 4. Real-time Processing\n",
    "Real-time processing allows systems to process and respond to data immediately. This is crucial in applications such as live data analysis, monitoring systems, and interactive applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Hello, World!\n",
      "< Request served by 7811941c69e658\n"
     ]
    }
   ],
   "source": [
    "import asyncio\n",
    "import websockets\n",
    "    \n",
    "async def hello():\n",
    "    uri = \"wss://echo.websocket.org\"  # Example echo websocket\n",
    "    async with websockets.connect(uri) as websocket:\n",
    "        message = \"Hello, World!\"\n",
    "        print(f\"> {message}\")  # Print the message being sent\n",
    "        await websocket.send(message)\n",
    "        response = await websocket.recv()\n",
    "        print(f\"< {response}\")  # Print the server's response\n",
    "\n",
    "# Running the websocket example\n",
    "await hello()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Websockets can be used for real-time communication between client and server, enabling immediate data exchange.\n",
    "\n",
    "## 5. Conclusion\n",
    "Optimizing through GPUs, cloud services, and real-time processing can significantly enhance application performance. GPUs accelerate parallel computations, cloud services provide scalable and flexible resources, and real-time processing enables immediate data handling. By combining these technologies, applications can become more efficient and responsive.\n",
    "\n",
    "This notebook has provided a brief overview of the key concepts and applications of these optimization methods."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
